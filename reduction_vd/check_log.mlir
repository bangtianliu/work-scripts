// -----// IR Dump After AutoInputConversionPipelinePass (iree-auto-input-conversion) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  func.func @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After IREEImportPublicPass (iree-import-public) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After ImportMLProgramPass (iree-import-ml-program) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After SanitizeModuleNamesPass (iree-sanitize-module-names) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After ConvertShardToFlowPass (iree-convert-shard-to-flow) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After DemoteF64ToF32Pass (iree-input-conversion-demote-f64-to-f32) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = util.call @_reduce(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
  util.func private @_reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> attributes {hal.abi.convention = #hal.abi.convention<synchronous>} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = tensor.empty() : tensor<8xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
    %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %3 = arith.addf %in, %out : f32
      linalg.yield %3 : f32
    } -> tensor<8xf32>
    util.return %2 : tensor<8xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @_reduce(%arg0: tensor<8x64xf32>) -> tensor<8xf32> attributes {hal.abi.convention = #hal.abi.convention<synchronous>} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = tensor.empty() : tensor<8xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<8xf32>) -> tensor<8xf32>
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<8x64xf32>) outs(%1 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %3 = arith.addf %in, %out : f32
    linalg.yield %3 : f32
  } -> tensor<8xf32>
  util.return %2 : tensor<8xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = util.call @_reduce(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module {
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module attributes {hal.device.targets = [#hal.device.alias<"hip"> : !hal.device]} {
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #hal.device.alias<"hip"> : !hal.device
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #hal.device.alias<"hip"> : !hal.device
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After AttrBasedPipelinePass (iree-preprocessing-attr-based-pipeline) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After WarnOnUninitializedValuesPass (iree-global-opt-warn-on-uninitialized-values) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedConvToConvPass (iree-global-opt-quantized-conv-to-conv) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedMatmulToMatmulPass (iree-global-opt-quantized-matmul-to-matmul) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RemoveZeroExtentTensorsPass (iree-global-opt-remove-zero-extent-tensors) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOpsPass (iree-global-opt-detach-elementwise-from-named-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyDepthwiseConvPass (simplify-depthwise-conv) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperandsPass (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapesPass (iree-global-opt-expand-tensor-shapes) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = tensor.empty() : tensor<8xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalgPass (convert-elementwise-to-linalg) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After DecomposeConcatPass (iree-global-opt-decompose-concat) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = tensor.empty() : tensor<8xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %5 = arith.addf %in, %out : f32
    linalg.yield %5 : f32
  } -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After InsertTensorBarriersPass (iree-dispatch-creation-insert-tensor-barriers) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-dispatch-creation-fold-unit-extent-dims) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteContractionInputsToBF16Pass (iree-global-opt-demote-contraction-inputs-to-bf16) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After PropagateLinalgTransposePass (iree-global-opt-propagate-linalg-transpose) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ConvertStridedContractionToContractionPass (iree-global-opt-convert-strided-contraction-to-contraction) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After GlobalLoopInvariantCodeMotionPass (iree-global-opt-loop-invariant-code-motion) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobalsPass (iree-consteval-jit-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After TensorPadToTensorInsertSlicePass (iree-dispatch-creation-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FusionPreprocessingPass (iree-dispatch-creation-fusion-preprocessing) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExpandShapesPass (iree-dispatch-creation-bubble-up-expand-shapes) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SinkReshapesPass (iree-dispatch-creation-sink-reshapes) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SplitReductionPass (iree-dispatch-creation-split-reduction-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FormSplitReductionDispatchesPass (iree-dispatch-creation-form-split-reduction-dispatches) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After TransposeGenericOpsPass (iree-dispatch-creation-transpose-generic-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After PropagateEncodingsPass (iree-dispatch-creation-propagate-encodings) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %cst = arith.constant -0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = tensor.empty() : tensor<8xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatchesPass (iree-dispatch-creation-form-scalar-dispatches) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %7 = arith.addf %in, %out : f32
    linalg.yield %7 : f32
  } -> tensor<8xf32>
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegionsPass (iree-dispatch-creation-form-dispatch-regions) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = flow.dispatch.region -> (tensor<8xf32>) {
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = flow.dispatch.region -> (tensor<8xf32>) {
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %cst = arith.constant -0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = tensor.empty() : tensor<8xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8xf32>) -> tensor<8xf32>
  %4 = flow.dispatch.region -> (tensor<8xf32>) {
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%3 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %5 = iree_tensor_ext.compute_barrier.end %4 : tensor<8xf32> -> tensor<8xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegionsPass (iree-dispatch-creation-clone-producers-into-dispatch-regions) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = flow.dispatch.region -> (tensor<8xf32>) {
    %5 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensionsPass (iree-dispatch-creation-collapse-dimensions) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = flow.dispatch.region -> (tensor<8xf32>) {
    %5 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After HoistUniformScalarComputePass (iree-dispatch-creation-hoist-uniform-scalar-compute) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = flow.dispatch.region -> (tensor<8xf32>) {
    %5 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FuseEncodingOpsIntoDispatchRegionsPass (iree-dispatch-creation-fuse-encoding-ops-into-dispatch-regions-pass) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = flow.dispatch.region -> (tensor<8xf32>) {
    %5 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ConvertEncodingToFlowPass (iree-dispatch-creation-convert-encoding-to-flow) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
  %2 = flow.dispatch.region -> (tensor<8xf32>) {
    %5 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    flow.return %7 : tensor<8xf32>
  }
  %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobalsPass (iree-util-hoist-into-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = iree_tensor_ext.compute_barrier.start %0 : tensor<8x64xf32> -> tensor<8x64xf32>
    %2 = flow.dispatch.region -> (tensor<8xf32>) {
      %5 = tensor.empty() : tensor<8xf32>
      %cst = arith.constant -0.000000e+00 : f32
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
      %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%1 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %8 = arith.addf %in, %out : f32
        linalg.yield %8 : f32
      } -> tensor<8xf32>
      flow.return %7 : tensor<8xf32>
    }
    %3 = iree_tensor_ext.compute_barrier.end %2 : tensor<8xf32> -> tensor<8xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After RemoveTensorBarriersPass (iree-dispatch-creation-remove-tensor-barriers) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.region -> (tensor<8xf32>) {
    %3 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
    %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %6 = arith.addf %in, %out : f32
      linalg.yield %6 : f32
    } -> tensor<8xf32>
    flow.return %5 : tensor<8xf32>
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ConvertDispatchRegionsToWorkgroupsPass (iree-dispatch-creation-convert-dispatch-regions-to-workgroups) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %cst = arith.constant -0.000000e+00 : f32
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ConvertTensorToFlowPass (iree-dispatch-creation-convert-tensor-to-flow) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After MaterializeDefaultWorkgroupCountRegionPass (iree-dispatch-creation-materialize-default-workgroup-count-region) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After BitcastUnsupportedElementTypesPass (iree-dispatch-creation-bitcast-unsupported-element-types) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After VerifyInputLegalityPass (iree-verify-input-legality) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
        (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
      %cst = arith.constant -0.000000e+00 : f32
      %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %4 = tensor.empty() : tensor<8xf32>
      %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
      %6 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %7 = arith.addf %in, %out : f32
        linalg.yield %7 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
        (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
      %cst = arith.constant -0.000000e+00 : f32
      %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %4 = tensor.empty() : tensor<8xf32>
      %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
      %6 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %7 = arith.addf %in, %out : f32
        linalg.yield %7 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After AttributeCallGraphPass (iree-util-attribute-call-graph) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
        (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
      %cst = arith.constant -0.000000e+00 : f32
      %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %4 = tensor.empty() : tensor<8xf32>
      %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
      %6 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %7 = arith.addf %in, %out : f32
        linalg.yield %7 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After InitializeEmptyTensorsPass (iree-flow-initialize-empty-tensors) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CaptureDynamicDimsPass (iree-flow-capture-dynamic-dims) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
      (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
    %cst = arith.constant -0.000000e+00 : f32
    %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
    %4 = tensor.empty() : tensor<8xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %7 = arith.addf %in, %out : f32
      linalg.yield %7 : f32
    } -> tensor<8xf32>
    iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchExternsPass (iree-flow-outline-dispatch-externs) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch.workgroups(%0) : (tensor<8x64xf32>) -> tensor<8xf32> =
        (%arg1: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg2: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
      %cst = arith.constant -0.000000e+00 : f32
      %3 = iree_tensor_ext.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %4 = tensor.empty() : tensor<8xf32>
      %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
      %6 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %7 = arith.addf %in, %out : f32
        linalg.yield %7 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %6, %arg2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineDispatchRegionsPass (iree-flow-outline-dispatch-regions) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchesPass (iree-flow-annotate-dispatches) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOpsPass (iree-util-strip-debug-ops) //----- //
flow.executable private @reduce_dispatch_0 {
  flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
      %cst = arith.constant -0.000000e+00 : f32
      %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %1 = tensor.empty() : tensor<8xf32>
      %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
      %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %4 = arith.addf %in, %out : f32
        linalg.yield %4 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      return
    }
  }
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutablesPass (iree-flow-deduplicate-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CleanupTensorShapesPass (iree-flow-cleanup-tensor-shapes) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After OutlineConstantsPass (iree-flow-outline-constants) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizePass (iree-flow-canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputPass (iree-stream-verify-input) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
  %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
  %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After CloneToConsumersPass (iree-stream-clone-to-consumers) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @reduce_dispatch_0 {
    flow.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>, %arg1: !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>) {
        %cst = arith.constant -0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %1 = tensor.empty() : tensor<8xf32>
        %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<8xf32>) -> tensor<8xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%0 : tensor<8x64xf32>) outs(%2 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %4 = arith.addf %in, %out : f32
          linalg.yield %4 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %3, %arg1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<8x64xf32>
    %1 = flow.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0) : (tensor<8x64xf32>) -> tensor<8xf32>
    %2 = hal.tensor.export %1 "output0" : tensor<8xf32> -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStreamPass (iree-stream-conversion) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %cst = arith.constant -0.000000e+00 : f32
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%3} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensorsPass (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %cst = arith.constant -0.000000e+00 : f32
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%3} from(#hal.device.affinity<@__device_0>) -> to(#hal.device.affinity<@__device_0>) !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializersPass (iree-util-combine-initializers) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After SpecializeEncodingsPass (iree-stream-specialize-encodings) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
    %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
    %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
    %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
    %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @reduce_dispatch_0 {
  stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
      %cst = arith.constant -0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %3 = tensor.empty() : tensor<8xf32>
      %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
      %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %6 = arith.addf %in, %out : f32
        linalg.yield %6 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8x64xf32> : index
  %1 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%0}
  %2 = stream.async.clone on(#hal.device.affinity<@__device_0>) %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %3 = stream.tensor.sizeof on(#hal.device.affinity<@__device_0>) tensor<8xf32> : index
  %4 = stream.tensor.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%2) : (tensor<8x64xf32> in !stream.resource<*>{%0}) -> tensor<8xf32> in !stream.resource<*>{%3}
  %5 = stream.async.clone on(#hal.device.affinity<@__device_0>) %4 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %6 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %5 : tensor<8xf32> in !stream.resource<external>{%3} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After EncodeHostTensorsPass (iree-stream-encode-host-tensors) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After MaterializeEncodingsPass (iree-stream-materialize-encodings) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncResourcesPass (iree-stream-verify-lowering-to-async-resources) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWritePass (iree-stream-materialize-copy-on-write) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocationsPass (iree-stream-emplace-allocations) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<*>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<*>{%c2048}) -> !stream.resource<*>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<*>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RefineUsagePass (iree-stream-refine-usage) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<external>{%c2048}
    %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c32} -> !stream.resource<external>{%c32}
    %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.clone on(#hal.device.affinity<@__device_0>) %0 : !stream.resource<external>{%c2048} -> !stream.resource<external>{%c2048}
  %2 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %3 = stream.async.clone on(#hal.device.affinity<@__device_0>) %2 : !stream.resource<external>{%c32} -> !stream.resource<external>{%c32}
  %4 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %3 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRangesPass (iree-stream-verify-async-access-ranges) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.async.dispatch on(#hal.device.affinity<@__device_0>) @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%0[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecutionPass (iree-stream-schedule-execution) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrencyPass (iree-stream-schedule-concurrency) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After SyncInitializersPass (iree-stream-sync-initializers) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %3 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After PropagateTimepointsPass (iree-stream-propagate-timepoints) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.timepoint.immediate => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%1) => with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %4 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %4 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltinsPass (iree-stream-materialize-builtins) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %1 = stream.timepoint.immediate => !stream.timepoint
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) await(%1) => with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %4 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %4 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
    %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
    stream.yield %3 : !stream.resource<external>{%c32}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
  %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %2 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %3 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %3 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %3 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncPass (iree-stream-verify-lowering-to-async) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %results, %result_timepoint = stream.async.execute on(#hal.device.affinity<@__device_0>) with(%0 as %arg1: !stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32} {
      %3 = stream.async.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%arg1[%c0 to %c2048 for %c2048]) : (!stream.resource<external>{%c2048}) -> !stream.resource<external>{%c32}
      stream.yield %3 : !stream.resource<external>{%c32}
    } => !stream.timepoint
    %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c32}
    %2 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %1 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocationPass (iree-stream-schedule-allocation) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After EmplaceTransientsPass (iree-stream-emplace-transients) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTransientSizeQueriesPass (iree-stream-materialize-transient-size-queries) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstantsPass (iree-stream-pack-constants) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlicesPass (iree-stream-layout-slices) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubrangesPass (iree-util-propagate-subranges) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AutomaticReferenceCountingPass (iree-stream-automatic-reference-counting) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateConstantTransientSizePass (iree-stream-annotate-constant-transient-size) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmdPass (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ReuseAllocationsPass (iree-stream-reuse-allocations) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {iree.fixedpoint.iteration = 0 : index, stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindingsPass (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0, %c0 : index, index) {
        ro %arg1[%c0_0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArgumentsPass (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: index {stream.values = [0 : index]}, %arg3: index {stream.values = [0 : index]}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%arg3] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0, %c0 : index, index) {
        ro %arg1[%c0_0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchAssumptionsPass (iree-stream-annotate-dispatch-assumptions) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: index {stream.values = [0 : index]}, %arg3: index {stream.values = [0 : index]}) {
        %0:2 = util.assume.int 
            %arg2<umin = 0, umax = 0>, 
            %arg3<umin = 0, umax = 0>
          : index, index
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %1 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %2 = stream.binding.subspan %arg1[%0#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %3 = iree_tensor_ext.dispatch.tensor.load %1, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %4 = tensor.empty() : tensor<8xf32>
        %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%3 : tensor<8x64xf32>) outs(%5 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %7 = arith.addf %in, %out : f32
          linalg.yield %7 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %6, %2, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0, %c0 : index, index) {
        ro %arg1[%c0_0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperandsPass (iree-stream-pack-dispatch-operands) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %c32_i64 = arith.constant 32 : i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %c32_i64_0 = arith.constant 32 : i64
        %7 = arith.shli %6, %c32_i64_0 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10:2 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>
          : index, index
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %11 = stream.binding.subspan %arg0[%10#0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %12 = stream.binding.subspan %arg1[%10#1] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %13 = iree_tensor_ext.dispatch.tensor.load %11, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %14 = tensor.empty() : tensor<8xf32>
        %15 = linalg.fill ins(%cst : f32) outs(%14 : tensor<8xf32>) -> tensor<8xf32>
        %16 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%13 : tensor<8x64xf32>) outs(%15 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %17 = arith.addf %in, %out : f32
          linalg.yield %17 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %16, %12, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7 : i32, i32, i32, i32) {
        ro %arg1[%c0_0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0_0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperandsPass (iree-stream-fold-uniform-operands) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AttributeCallGraphPass (iree-util-attribute-call-graph) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
  %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
  %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
    stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
      ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
      wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
  %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @reduce_dispatch_0 {
    stream.executable.export public @reduce_dispatch_0_reduction_8x64_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}) {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
        %3 = tensor.empty() : tensor<8xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
        %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
        ^bb0(%in: f32, %out: f32):
          %6 = arith.addf %in, %out : f32
          linalg.yield %6 : f32
        } -> tensor<8xf32>
        iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
        return
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @reduce_dispatch_0_reduction_8x64_f32() {
          %cst = arith.constant -0.000000e+00 : f32
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
          %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
          %3 = tensor.empty() : tensor<8xf32>
          %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
          %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
          ^bb0(%in: f32, %out: f32):
            %6 = arith.addf %in, %out : f32
            linalg.yield %6 : f32
          } -> tensor<8xf32>
          iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
          return
        }
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0)>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) count(%arg0: !hal.device) -> (index, index, index) {
        %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @reduce_dispatch_0_reduction_8x64_f32() {
          %cst = arith.constant -0.000000e+00 : f32
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
          %1 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
          %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
          %3 = tensor.empty() : tensor<8xf32>
          %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
          %5 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
          ^bb0(%in: f32, %out: f32):
            %6 = arith.addf %in, %out : f32
            linalg.yield %6 : f32
          } -> tensor<8xf32>
          iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
          return
        }
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import on(#hal.device.affinity<@__device_0>) %arg0 : !hal.buffer_view -> tensor<8x64xf32> in !stream.resource<external>{%c2048}
    %result, %result_timepoint = stream.resource.alloca uninitialized on(#hal.device.affinity<@__device_0>) : !stream.resource<external>{%c32} => !stream.timepoint
    %1 = stream.cmd.execute on(#hal.device.affinity<@__device_0>) await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c2048}, %result as %arg2: !stream.resource<external>{%c32}) {
      stream.cmd.dispatch @reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32 {
        ro %arg1[%c0 for %c2048] : !stream.resource<external>{%c2048},
        wo %arg2[%c0 for %c32] : !stream.resource<external>{%c32}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c32}
    %3 = stream.tensor.export on(#hal.device.affinity<@__device_0>) %2 : tensor<8xf32> in !stream.resource<external>{%c32} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After SpecializeExportsPass (iree-codegen-specialize-exports) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32() {
      %cst = arith.constant -0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
      %3 = tensor.empty() : tensor<8xf32>
      %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
      %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
      ^bb0(%in: f32, %out: f32):
        %6 = arith.addf %in, %out : f32
        linalg.yield %6 : f32
      } -> tensor<8xf32>
      iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
      return
    }
  }
}

// -----// IR Dump After MaterializeDeviceEncodingPass (iree-codegen-materialize-device-encoding) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After GPUGeneralizeNamedOpsPass (iree-codegen-gpu-generalize-named-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After ROCDLConfigureBufferInstructionsPass (iree-rocdl-configure-buffer-instructions) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After TypePropagationPass (iree-codegen-type-propagation) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After BubbleUpOrdinalOpsPass (iree-codegen-bubble-up-ordinal-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatchesPass (iree-codegen-bufferize-copy-only-dispatches) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After DecomposeSoftmaxPass (iree-codegen-decompose-softmax) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %2 = iree_tensor_ext.dispatch.tensor.load %0, offsets = [0, 0], sizes = [8, 64], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>> -> tensor<8x64xf32>
  %3 = tensor.empty() : tensor<8xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<8xf32>) -> tensor<8xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%2 : tensor<8x64xf32>) outs(%4 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %6 = arith.addf %in, %out : f32
    linalg.yield %6 : f32
  } -> tensor<8xf32>
  iree_tensor_ext.dispatch.tensor.store %5, %1, offsets = [0], sizes = [8], strides = [1] : tensor<8xf32> -> !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  return
}

// -----// IR Dump After BufferizeDispatchTensorLoadStorePass (iree-codegen-bufferize-dispatch-tensor-load-store) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<readonly:tensor<8x64xf32>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : !iree_tensor_ext.dispatch.tensor<writeonly:tensor<8xf32>>
  %6 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %7 = tensor.empty() : tensor<8xf32>
  %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<8xf32>) -> tensor<8xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%6 : tensor<8x64xf32>) outs(%8 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %10 = arith.addf %in, %out : f32
    linalg.yield %10 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %9, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUCombineLayoutTransformationPass (iree-codegen-gpu-combine-layout-transformation) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %8 = arith.addf %in, %out : f32
    linalg.yield %8 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUGeneralizeNamedOpsPass (iree-codegen-gpu-generalize-named-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %8 = arith.addf %in, %out : f32
    linalg.yield %8 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After BlockDynamicDimensionsPass (iree-codegen-block-dynamic-dimensions) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %8 = arith.addf %in, %out : f32
    linalg.yield %8 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %8 = arith.addf %in, %out : f32
    linalg.yield %8 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
  %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
  ^bb0(%in: f32, %out: f32):
    %8 = arith.addf %in, %out : f32
    linalg.yield %8 : f32
  } -> tensor<8xf32>
  iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After MaterializeTuningSpecsPass (iree-codegen-materialize-tuning-specs) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant -0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
    %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
    %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
    %5 = tensor.empty() : tensor<8xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    return
  }
}

// -----// IR Dump After MaterializeUserConfigsPass (iree-codegen-materialize-user-configs) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant -0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
    %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
    %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
    %5 = tensor.empty() : tensor<8xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    return
  }
}

// -----// IR Dump After LLVMGPUSelectLoweringStrategyPass (iree-llvmgpu-select-lowering-strategy) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
    %cst = arith.constant -0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
    %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
    %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
    %5 = tensor.empty() : tensor<8xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    return
  }
}

// -----// IR Dump After ConfigureTargetExecutableVariantsPass (iree-hal-configure-target-executable-variants) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
      %cst = arith.constant -0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
      %5 = tensor.empty() : tensor<8xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
      %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
      ^bb0(%in: f32, %out: f32):
        %8 = arith.addf %in, %out : f32
        linalg.yield %8 : f32
      } -> tensor<8xf32>
      iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      return
    }
  }
}

// -----// IR Dump After ConfigureExecutablesPass (iree-hal-configure-executables) //----- //
hal.executable private @reduce_dispatch_0 {
  hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
    hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
      hal.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
        %cst = arith.constant -0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
        %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
        %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
        %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
        %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
        %5 = tensor.empty() : tensor<8xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
        %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
        ^bb0(%in: f32, %out: f32):
          %8 = arith.addf %in, %out : f32
          linalg.yield %8 : f32
        } -> tensor<8xf32>
        iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
        return
      }
    }
  }
}

// -----// IR Dump After HoistExecutableObjectsPass (iree-hal-hoist-executable-objects) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
      %cst = arith.constant -0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
      %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
      %5 = tensor.empty() : tensor<8xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
      %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
      ^bb0(%in: f32, %out: f32):
        %8 = arith.addf %in, %out : f32
        linalg.yield %8 : f32
      } -> tensor<8xf32>
      iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      return
    }
  }
}

// -----// IR Dump After LowerExecutableUsingTransformDialectPass (iree-codegen-lower-executable-using-transform-dialect) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
    %cst = arith.constant -0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
    %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
    %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
    %5 = tensor.empty() : tensor<8xf32>
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<8xf32>) -> tensor<8xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%4 : tensor<8x64xf32>) outs(%6 : tensor<8xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %8 = arith.addf %in, %out : f32
      linalg.yield %8 : f32
    } -> tensor<8xf32>
    iree_codegen.store_to_buffer %7, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    return
  }
}

// -----// IR Dump After TileAndDistributeToWorkgroupsUsingForallOpPass (iree-codegen-tile-and-distribute-to-workgroups-using-forall-op) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After RematerializeParallelOpsPass (iree-codegen-rematerialize-parallel-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConvertAttentionToOnlineAttentionPass (iree-linalg-ext-convert-attention-to-online-attention) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUPromoteMatmulOperandsPass (iree-codegen-gpu-promote-matmul-operands) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%7 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %8 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUApplyPaddingLevelPass (iree-codegen-gpu-apply-padding-level) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst : f32) outs(%extracted_slice_0 : tensor<1xf32>) -> tensor<1xf32>
    %8 = ub.poison : f32
    %padded = tensor.pad %extracted_slice low[0, 0] high[0, 0] {
    ^bb0(%arg2: index, %arg3: index):
      tensor.yield %8 : f32
    } : tensor<1x64xf32> to tensor<1x64xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.copy ins(%padded : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %11 = ub.poison : f32
    %padded_1 = tensor.pad %7 low[0] high[0] {
    ^bb0(%arg2: index):
      tensor.yield %11 : f32
    } : tensor<1xf32> to tensor<1xf32>
    %12 = tensor.empty() : tensor<1xf32>
    %13 = linalg.copy ins(%padded_1 : tensor<1xf32>) outs(%12 : tensor<1xf32>) -> tensor<1xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%10 : tensor<1x64xf32>) outs(%13 : tensor<1xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %cst_3 = arith.constant 0.000000e+00 : f32
      %true = arith.constant true
      %15 = arith.addf %in, %out : f32
      linalg.yield %15 : f32
    } -> tensor<1xf32>
    %extracted_slice_2 = tensor.extract_slice %14[0] [1] [1] : tensor<1xf32> to tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %extracted_slice_2 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<1xf32>
    %7 = linalg.fill ins(%cst_0 : f32) outs(%extracted_slice : tensor<1xf32>) -> tensor<1xf32>
    %8 = tensor.empty() : tensor<1xf32>
    %9 = linalg.copy ins(%7 : tensor<1xf32>) outs(%8 : tensor<1xf32>) -> tensor<1xf32>
    %10 = tensor.empty() : tensor<1x64xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %12 = tensor.empty() : tensor<1x64xf32>
    %13 = linalg.copy ins(%extracted_slice_1 : tensor<1x64xf32>) outs(%12 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%13 : tensor<1x64xf32>) outs(%11 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %15 = arith.addf %in, %out : f32
      linalg.yield %15 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%14 : tensor<1x64xf32>) outs(%9 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %15 = arith.addf %in, %init : f32
        linalg.yield %15 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = tensor.empty() : tensor<1x64xf32>
    %12 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%11 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %14 = arith.addf %in, %out : f32
      linalg.yield %14 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%13 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %14 = arith.addf %in, %init : f32
        linalg.yield %14 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ResolveShapedTypeResultDimsPass (resolve-shaped-type-result-dims) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After SimplifyAffineMinMaxPass (affine-simplify-min-max) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ReifyResultShapesPass (reify-result-shapes) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUApplyTilingLevelPass (iree-codegen-gpu-apply-tiling-level) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After DecomposeAttentionPass (iree-linalg-ext-decompose-attention) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ConfigTrackingCanonicalizerPass (iree-codegen-config-tracking-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After DecomposeHorizontallyFusedGemmsPass (iree-codegen-gpu-decompose-horizontally-fused-gemms) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11 : tensor<1x64xf32>) outs(%10 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %13 = arith.addf %in, %out : f32
      linalg.yield %13 : f32
    } -> tensor<1x64xf32>
    %reduced = linalg.reduce ins(%12 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %13 = arith.addf %in, %init : f32
        linalg.yield %13 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LLVMGPUConfigureTensorLayoutsPass (iree-llvmgpu-configure-tensor-layouts) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %13 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x64xf32>) outs(%13 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<1x64xf32>
    %15 = iree_vector_ext.to_layout %14 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %reduced = linalg.reduce ins(%15 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %16 = arith.addf %in, %init : f32
        linalg.yield %16 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.copy ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) -> tensor<1x64xf32>
    %12 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %13 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x64xf32>) outs(%13 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<1x64xf32>
    %15 = iree_vector_ext.to_layout %14 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %reduced = linalg.reduce ins(%15 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) dimensions = [1] 
      (%in: f32, %init: f32) {
        %16 = arith.addf %in, %init : f32
        linalg.yield %16 : f32
      }
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %reduced into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LinalgGeneralizeNamedOpsPass (linalg-generalize-named-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> ()>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%cst : f32) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %12 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %13 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x64xf32>) outs(%13 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %17 = arith.addf %in, %out : f32
      linalg.yield %17 : f32
    } -> tensor<1x64xf32>
    %15 = iree_vector_ext.to_layout %14 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%15 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %17 = arith.addf %in, %out : f32
      linalg.yield %17 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-linalg-ext-fold-unit-extent-dims) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> ()>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%cst : f32) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %12 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %13 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%12 : tensor<1x64xf32>) outs(%13 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %17 = arith.addf %in, %out : f32
      linalg.yield %17 : f32
    } -> tensor<1x64xf32>
    %15 = iree_vector_ext.to_layout %14 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1, 1], batch_tile = [1, 1], outer_tile = [1, 1], thread_tile = [1, 64], element_tile = [1, 1], subgroup_strides = [0, 0], thread_strides = [0, 1]>) : tensor<1x64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%15 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %17 = arith.addf %in, %out : f32
      linalg.yield %17 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After VectorExtFoldUnitExtentDimsPass (iree-vector-ext-fold-unit-extent-dims) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst_0 : f32) outs(%7 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1xf32>
    %9 = tensor.empty() : tensor<1x64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> ()>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%cst : f32) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice : tensor<1x64xf32>) outs(%9 : tensor<1x64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %11[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %12 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = tensor.empty() : tensor<1x64xf32>
    %inserted_slice = tensor.insert_slice %12 into %13[0, 0] [1, 64] [1, 1] : tensor<64xf32> into tensor<1x64xf32>
    %extracted_slice_2 = tensor.extract_slice %10[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %14 = iree_vector_ext.to_layout %extracted_slice_2 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = tensor.empty() : tensor<1x64xf32>
    %inserted_slice_3 = tensor.insert_slice %14 into %15[0, 0] [1, 64] [1, 1] : tensor<64xf32> into tensor<1x64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%inserted_slice : tensor<1x64xf32>) outs(%inserted_slice_3 : tensor<1x64xf32>) attrs =  {lowering_config = #iree_gpu.lowering_config<{lane_basis = [[1, 64], [0, 1]], partial_reduction = [0, 64], subgroup_basis = [[1, 1], [0, 1]], thread = [0, 1], workgroup = [1, 0]}>} {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.addf %in, %out : f32
      linalg.yield %20 : f32
    } -> tensor<1x64xf32>
    %extracted_slice_4 = tensor.extract_slice %16[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %17 = iree_vector_ext.to_layout %extracted_slice_4 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %18 = tensor.empty() : tensor<1x64xf32>
    %inserted_slice_5 = tensor.insert_slice %17 into %18[0, 0] [1, 64] [1, 1] : tensor<64xf32> into tensor<1x64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0)>], iterator_types = ["parallel", "reduction"]} ins(%inserted_slice_5 : tensor<1x64xf32>) outs(%8 : tensor<1xf32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.addf %in, %out : f32
      linalg.yield %20 : f32
    } -> tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %19 into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After LinalgFoldUnitExtentDimsPass (linalg-fold-unit-extent-dims) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = tensor.empty() : tensor<f32>
    %9 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %10 = tensor.empty() : tensor<64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %12 = tensor.empty() : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%12 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %16 = tensor.empty() : tensor<64xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%14, %15 : tensor<64xf32>, tensor<64xf32>) outs(%16 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %20 = arith.addf %in, %in_2 : f32
      linalg.yield %20 : f32
    } -> tensor<64xf32>
    %18 = iree_vector_ext.to_layout %17 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %19 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%18 : tensor<64xf32>) outs(%9 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %20 = arith.addf %in, %out : f32
      linalg.yield %20 : f32
    } -> tensor<f32>
    %inserted_slice = tensor.insert_slice %19 into %7[0] [1] [1] : tensor<f32> into tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %inserted_slice into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = tensor.empty() : tensor<f32>
    %9 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %10 = tensor.empty() : tensor<64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %12 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %14 = tensor.empty() : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%12, %13 : tensor<64xf32>, tensor<64xf32>) outs(%14 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %18 = arith.addf %in, %in_2 : f32
      linalg.yield %18 : f32
    } -> tensor<64xf32>
    %16 = iree_vector_ext.to_layout %15 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %17 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%16 : tensor<64xf32>) outs(%9 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %18 = arith.addf %in, %out : f32
      linalg.yield %18 : f32
    } -> tensor<f32>
    %inserted_slice = tensor.insert_slice %17 into %7[0] [1] [1] : tensor<f32> into tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %inserted_slice into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<1xf32>
    %8 = tensor.empty() : tensor<f32>
    %9 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %10 = tensor.empty() : tensor<64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %12 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %14 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%12, %13 : tensor<64xf32>, tensor<64xf32>) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %17 = arith.addf %in, %in_2 : f32
      linalg.yield %17 : f32
    } -> tensor<64xf32>
    %15 = iree_vector_ext.to_layout %14 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %16 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%15 : tensor<64xf32>) outs(%9 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %17 = arith.addf %in, %out : f32
      linalg.yield %17 : f32
    } -> tensor<f32>
    %inserted_slice = tensor.insert_slice %16 into %7[0] [1] [1] : tensor<f32> into tensor<1xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %inserted_slice into %arg1[%arg0] [1] [1] : tensor<1xf32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After FoldTensorSubsetOpsPass (fold-tensor-subset-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After VectorizeIREELinalgExtOpsPass (iree-linalg-ext-vectorize-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After DecomposeConvolutionToLowerDimOpsPass (iree-codegen-decompose-convolution-to-lower-dim-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After DecomposeIm2colPass (iree-linalg-ext-decompose-im2col) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %1 = amdgpu.fat_raw_buffer_cast %0 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %2 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = iree_codegen.load_from_buffer %1 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %5 = tensor.empty() : tensor<8xf32>
  %6 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %5) -> (tensor<8xf32>) {
    %7 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %4[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%7 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %9 = tensor.empty() : tensor<64xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %11 = iree_vector_ext.to_layout %extracted_slice_1 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %12 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %13 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%11, %12 : tensor<64xf32>, tensor<64xf32>) outs(%9 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %16 = arith.addf %in, %in_2 : f32
      linalg.yield %16 : f32
    } -> tensor<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : tensor<64xf32>
    %15 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%14 : tensor<64xf32>) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %16 = arith.addf %in, %out : f32
      linalg.yield %16 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %6, %3 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After VectorizeIREEVectorExtOpsPass (iree-vector-ext-vectorize-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %0 = ub.poison : f32
  %cst = arith.constant 0.000000e+00 : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %5[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %9 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%cst_0 : f32) outs(%8 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<f32>
    %10 = tensor.empty() : tensor<64xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%cst : f32) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<64xf32>
    %12 = vector.transfer_read %extracted_slice_1[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = tensor.empty() : tensor<64xf32>
    %15 = vector.transfer_write %13, %14[%c0] {in_bounds = [true]} : vector<64xf32>, tensor<64xf32>
    %16 = vector.transfer_read %11[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %17 = iree_vector_ext.to_layout %16 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %18 = tensor.empty() : tensor<64xf32>
    %19 = vector.transfer_write %17, %18[%c0] {in_bounds = [true]} : vector<64xf32>, tensor<64xf32>
    %20 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%15, %19 : tensor<64xf32>, tensor<64xf32>) outs(%10 : tensor<64xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %26 = arith.addf %in, %in_2 : f32
      linalg.yield %26 : f32
    } -> tensor<64xf32>
    %21 = vector.transfer_read %20[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %22 = iree_vector_ext.to_layout %21 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %23 = tensor.empty() : tensor<64xf32>
    %24 = vector.transfer_write %22, %23[%c0] {in_bounds = [true]} : vector<64xf32>, tensor<64xf32>
    %25 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = ["reduction"]} ins(%24 : tensor<64xf32>) outs(%9 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %26 = arith.addf %in, %out : f32
      linalg.yield %26 : f32
    } -> tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %25 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GenericVectorizationPass (iree-codegen-generic-vectorization) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<-0.000000e+00> : vector<f32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_1 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %5[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %9 = vector.transfer_write %cst, %8[] : vector<f32>, tensor<f32>
    %10 = vector.transfer_read %extracted_slice_2[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %11 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = iree_vector_ext.to_layout %cst_0 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %13 = arith.addf %11, %12 : vector<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %15 = vector.multi_reduction <add>, %14, %cst_1 [0] : vector<64xf32> to f32
    %16 = vector.broadcast %15 : f32 to vector<f32>
    %17 = vector.transfer_write %16, %9[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %17 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %5[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %9 = vector.transfer_read %extracted_slice_1[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %extracted_slice = tensor.extract_slice %5[%arg0, 0] [1, 64] [1, 1] : tensor<8x64xf32> to tensor<1x64xf32>
    %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0] [1, 64] [1, 1] : tensor<1x64xf32> to tensor<64xf32>
    %9 = vector.transfer_read %extracted_slice_1[%c0], %0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After OptimizeTensorInsertExtractSlicesPass (iree-codegen-optimize-tensor-insert-extract-slices) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUVectorAllocPass (iree-codegen-gpu-vector-alloc) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After GPUCombineValueBarriersPass (iree-codegen-gpu-combine-value-barriers) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ROCDLConfigureBufferInstructionsPass (iree-rocdl-configure-buffer-instructions) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = tensor.empty() : tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %8 = tensor.empty() : tensor<f32>
    %9 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %10 = iree_vector_ext.to_layout %9 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = arith.addf %10, %11 : vector<64xf32>
    %13 = iree_vector_ext.to_layout %12 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %14 = vector.multi_reduction <add>, %13, %cst_0 [0] : vector<64xf32> to f32
    %15 = vector.broadcast %14 : f32 to vector<f32>
    %16 = vector.transfer_write %15, %8[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %16 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After EliminateEmptyTensorsPass (iree-eliminate-empty-tensors) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = iree_codegen.load_from_buffer %4 : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8xf32>
  %7 = tensor.empty() : tensor<8xf32>
  %8 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<f32>
    %9 = tensor.empty() : tensor<f32>
    %10 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %11 = iree_vector_ext.to_layout %10 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %12 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %13 = arith.addf %11, %12 : vector<64xf32>
    %14 = iree_vector_ext.to_layout %13 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %15 = vector.multi_reduction <add>, %14, %cst_0 [0] : vector<64xf32> to f32
    %16 = vector.broadcast %15 : f32 to vector<f32>
    %17 = vector.transfer_write %16, %extracted_slice[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %17 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %8, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After EmptyTensorToAllocTensorPass (empty-tensor-to-alloc-tensor) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %5 = iree_codegen.load_from_buffer %2 : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8x64xf32>
  %6 = iree_codegen.load_from_buffer %4 : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> -> tensor<8xf32>
  %7 = scf.forall (%arg0) in (8) shared_outs(%arg1 = %6) -> (tensor<8xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[%arg0] [1] [1] : tensor<8xf32> to tensor<f32>
    %8 = vector.transfer_read %5[%arg0, %c0], %0 {in_bounds = [true]} : tensor<8x64xf32>, vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %11 = arith.addf %9, %10 : vector<64xf32>
    %12 = iree_vector_ext.to_layout %11 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %13 = vector.multi_reduction <add>, %12, %cst_0 [0] : vector<64xf32> to f32
    %14 = vector.broadcast %13 : f32 to vector<f32>
    %15 = vector.transfer_write %14, %extracted_slice[] : vector<f32>, tensor<f32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %15 into %arg1[%arg0] [1] [1] : tensor<f32> into tensor<8xf32>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  iree_codegen.store_to_buffer %7, %4 : tensor<8xf32> into memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After IREEComprehensiveBufferizePass (iree-codegen-iree-comprehensive-bufferize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %1 resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %3 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %subview_1 = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    memref.copy %subview, %subview_1 : memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  memref.copy %4, %4 : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After IREEInjectAssumeAlignmentPass (iree-codegen-inject-assume-alignment) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %subview_2 = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    memref.copy %subview, %subview_2 : memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  memref.copy %4, %4 : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After ResolveShapedTypeResultDimsPass (resolve-shaped-type-result-dims) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %subview_2 = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    memref.copy %subview, %subview_2 : memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  memref.copy %4, %4 : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %subview_2 = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    memref.copy %subview, %subview_2 : memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    memref.copy %subview, %subview : memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREECodegenCanonicalizerPass (iree-codegen-canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CleanupBufferAllocViewPass (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMGPUCastTypeToFitMMAPass (iree-llvmgpu-cast-type-to-fit-mma) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %0 = ub.poison : f32
  %cst_0 = arith.constant -0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5 = vector.transfer_read %2[%arg0, %c0], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<64xf32>
    %6 = iree_vector_ext.to_layout %5 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %7 = iree_vector_ext.to_layout %cst to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %8 = arith.addf %6, %7 : vector<64xf32>
    %9 = iree_vector_ext.to_layout %8 to layout(#iree_vector_ext.nested_layout<subgroup_tile = [1], batch_tile = [1], outer_tile = [1], thread_tile = [64], element_tile = [1], subgroup_strides = [0], thread_strides = [1]>) : vector<64xf32>
    %10 = vector.multi_reduction <add>, %9, %cst_0 [0] : vector<64xf32> to f32
    %11 = vector.broadcast %10 : f32 to vector<f32>
    vector.transfer_write %11, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMGPUVectorDistributePass (iree-llvmgpu-vector-distribute) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_z = gpu.thread_id  z
  %thread_id_y = gpu.thread_id  y
  %thread_id_x = gpu.thread_id  x
  %1 = affine.linearize_index disjoint [%thread_id_z, %thread_id_y, %thread_id_x] by (1, 1, 64) : index
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %2, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %4, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %5 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %5[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %6:3 = affine.delinearize_index %1 into (1, 64) : index, index, index
    %7:2 = affine.delinearize_index %1 into (64) : index, index
    %8 = affine.linearize_index disjoint [%6#1, %c0, %c0, %7#1, %c0] by (1, 1, 1, 64, 1) : index
    %9 = vector.transfer_read %3[%arg0, %8], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %10 = vector.insert_strided_slice %9, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %11 = arith.addf %10, %cst_0 : vector<1x1x1xf32>
    %12 = vector.multi_reduction <add>, %11, %cst [0, 1, 2] : vector<1x1x1xf32> to f32
    %13 = gpu.subgroup_reduce  add %12 cluster(size = 64) : (f32) -> f32
    %14 = arith.cmpi eq, %1, %c0 : index
    scf.if %14 {
      %15 = vector.broadcast %13 : f32 to vector<f32>
      vector.transfer_write %15, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After DecomposeMapScatterPass (iree-linalg-ext-decompose-map-scatter) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_z = gpu.thread_id  z
  %thread_id_y = gpu.thread_id  y
  %thread_id_x = gpu.thread_id  x
  %1 = affine.linearize_index disjoint [%thread_id_z, %thread_id_y, %thread_id_x] by (1, 1, 64) : index
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %2, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %4 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %4, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %5 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %5[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %6:3 = affine.delinearize_index %1 into (1, 64) : index, index, index
    %7:2 = affine.delinearize_index %1 into (64) : index, index
    %8 = affine.linearize_index disjoint [%6#1, %c0, %c0, %7#1, %c0] by (1, 1, 1, 64, 1) : index
    %9 = vector.transfer_read %3[%arg0, %8], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %10 = vector.insert_strided_slice %9, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %11 = arith.addf %10, %cst_0 : vector<1x1x1xf32>
    %12 = vector.multi_reduction <add>, %11, %cst [0, 1, 2] : vector<1x1x1xf32> to f32
    %13 = gpu.subgroup_reduce  add %12 cluster(size = 64) : (f32) -> f32
    %14 = arith.cmpi eq, %1, %c0 : index
    scf.if %14 {
      %15 = vector.broadcast %13 : f32 to vector<f32>
      vector.transfer_write %15, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After GPUReduceBankConflictsPass (iree-codegen-gpu-reduce-bank-conflicts) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %subview = memref.subview %4[%arg0] [1] [1] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>> to memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %subview[] : vector<f32>, memref<f32, strided<[], offset: ?>, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After IREECodegenFoldMemRefAliasOpsPass (iree-codegen-fold-memref-alias-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After LLVMGPULowerExecutableTargetPass (iree-llvmgpu-lower-executable-target) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After VerifyWorkgroupDistributionPass (iree-codegen-verify-workgroup-distribution) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() attributes {translation_info = #iree_codegen.translation_info<pipeline = LLVMGPUVectorDistribute workgroup_size = [64, 1, 1] subgroup_size = 64, {gpu_pipeline_options = #iree_gpu.pipeline_options<no_reduce_shared_memory_bank_conflicts = false, use_igemm_convolution = false>}>} {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  scf.forall (%arg0) in (8) {
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%arg0, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%arg0] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
  } {mapping = [#iree_codegen.workgroup_mapping<x>]}
  return
}

// -----// IR Dump After ReconcileTranslationInfoPass (iree-codegen-reconcile-translation-info) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice()
    hal.return %x, %y, %z : index, index, index
  } attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32() {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = ub.poison : f32
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
      %thread_id_x = gpu.thread_id  x
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
      %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
      %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
      %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
      %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
      %10 = arith.addf %9, %cst : f32
      %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
      %12 = arith.cmpi eq, %thread_id_x, %c0 : index
      scf.if %12 {
        %13 = vector.broadcast %11 : f32 to vector<f32>
        vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      }
      iree_codegen.workgroup_count_hint(8)
      return
    }
  }
}

// -----// IR Dump After ResolveWorkgroupCountHintsPass (iree-codegen-resolve-workgroup-count-hints) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c8 = arith.constant 8 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c8, %c1, %c1_0 : index, index, index
  } attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
  builtin.module {
    func.func @reduce_dispatch_0_reduction_8x64_f32() {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = ub.poison : f32
      %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
      %thread_id_x = gpu.thread_id  x
      %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #hal.descriptor_type<storage_buffer>>
      %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #hal.descriptor_type<storage_buffer>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
      %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #hal.descriptor_type<storage_buffer>>
      %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #hal.descriptor_type<storage_buffer>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
      %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
      %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
      %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
      %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
      %10 = arith.addf %9, %cst : f32
      %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
      %12 = arith.cmpi eq, %thread_id_x, %c0 : index
      scf.if %12 {
        %13 = vector.broadcast %11 : f32 to vector<f32>
        vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
      }
      return
    }
  }
}

// -----// IR Dump After ConvertHALDescriptorTypeToGPUAddressSpacePass (iree-codegen-convert-hal-descriptor-type-to-gpu-address-space) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = ub.poison : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
    %thread_id_x = gpu.thread_id  x
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
    %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = ub.poison : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
    %thread_id_x = gpu.thread_id  x
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
    %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = ub.poison : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
    %thread_id_x = gpu.thread_id  x
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
    %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
    return
  }
}

// -----// IR Dump After LowerUKernelOpsToCallsPass (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = ub.poison : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
    %thread_id_x = gpu.thread_id  x
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
    %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
    return
  }
}

// -----// IR Dump After LinalgExtToLoopsPass (iree-linalg-ext-to-loops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After ConvertLinalgToLoopsPass (convert-linalg-to-loops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After PadDynamicAllocPass (iree-codegen-pad-dynamic-alloc) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After IREEBufferizeConstantsPass (iree-codegen-iree-bufferize-constants) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = ub.poison : f32
    %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
    %thread_id_x = gpu.thread_id  x
    %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
    %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
    %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
    %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
    %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
    %10 = arith.addf %9, %cst : f32
    %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
    %12 = arith.cmpi eq, %thread_id_x, %c0 : index
    scf.if %12 {
      %13 = vector.broadcast %11 : f32 to vector<f32>
      vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    }
    return
  }
}

// -----// IR Dump After FoldTensorExtractOpPass (iree-codegen-fold-tensor-extract-op) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = gpu.subgroup_reduce  add %10 cluster(size = 64) : (f32) -> f32
  %12 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %12 {
    %13 = vector.broadcast %11 : f32 to vector<f32>
    vector.transfer_write %13, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After ExpandGPUOpsPass (iree-codegen-expand-gpu-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_half_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_31(unit) {bound_ctrl = true} : f32
  %22 = arith.addf %21, %20 : f32
  %23 = rocdl.readlane %22, %c63_i32 : (f32, i32) -> f32
  %24 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %24 {
    %25 = vector.broadcast %23 : f32 to vector<f32>
    vector.transfer_write %25, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After GpuEliminateBarriers (gpu-eliminate-barriers) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_half_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_31(unit) {bound_ctrl = true} : f32
  %22 = arith.addf %21, %20 : f32
  %23 = rocdl.readlane %22, %c63_i32 : (f32, i32) -> f32
  %24 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %24 {
    %25 = vector.broadcast %23 : f32 to vector<f32>
    vector.transfer_write %25, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_half_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_31(unit) {bound_ctrl = true} : f32
  %22 = arith.addf %21, %20 : f32
  %23 = rocdl.readlane %22, %c63_i32 : (f32, i32) -> f32
  %24 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %24 {
    %25 = vector.broadcast %23 : f32 to vector<f32>
    vector.transfer_write %25, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_half_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_31(unit) {bound_ctrl = true} : f32
  %22 = arith.addf %21, %20 : f32
  %23 = rocdl.readlane %22, %c63_i32 : (f32, i32) -> f32
  %24 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %24 {
    %25 = vector.broadcast %23 : f32 to vector<f32>
    vector.transfer_write %25, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After ExtractAddressComputationGPUPass (extract-address-computation-gpu) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = ub.poison : f32
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %1 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %1, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %2 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %3 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %3, 64 : memref<8xf32, #gpu.address_space<global>>
  %4 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %5:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %6 = vector.transfer_read %2[%workgroup_id_x, %5#1], %0 {in_bounds = [true]} : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %7 = vector.insert_strided_slice %6, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %8 = arith.addf %7, %cst_0 : vector<1x1x1xf32>
  %9 = vector.extract %8[0, 0, 0] : f32 from vector<1x1x1xf32>
  %10 = arith.addf %9, %cst : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_half_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_31(unit) {bound_ctrl = true} : f32
  %22 = arith.addf %21, %20 : f32
  %23 = rocdl.readlane %22, %c63_i32 : (f32, i32) -> f32
  %24 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %24 {
    %25 = vector.broadcast %23 : f32 to vector<f32>
    vector.transfer_write %25, %4[%workgroup_id_x] : vector<f32>, memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  }
  return
}

// -----// IR Dump After VectorTransferLoweringPass (iree-codegen-vector-transfer-lowering) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREECodegenFoldMemRefAliasOpsPass (iree-codegen-fold-memref-alias-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After PropagateConstantOffsetsPass (iree-codegen-propagate-constant-offsets) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After ResolveSwizzleHintsPass (iree-codegen-resolve-swizzle-hints) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREEExpandStridedMetadataPass (iree-codegen-expand-strided-metadata) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After PropagateDispatchSizeBoundsPass (iree-codegen-propagate-dispatch-size-bounds) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After DecomposeAffineOpsPass (iree-codegen-decompose-affine-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4:2 = affine.delinearize_index %thread_id_x into (64) : index, index
  %5 = vector.load %1[%workgroup_id_x, %4#1] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %6 = vector.insert_strided_slice %5, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %7 = arith.addf %6, %cst_0 : vector<1x1x1xf32>
  %8 = vector.extract %7[0, 0, 0] : f32 from vector<1x1x1xf32>
  %9 = arith.addf %8, %cst : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_half_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_mirror(unit) {bound_ctrl = true} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %19 = arith.addf %17, %18 : f32
  %20 = amdgpu.dpp %19 %19  row_bcast_31(unit) {bound_ctrl = true} : f32
  %21 = arith.addf %20, %19 : f32
  %22 = rocdl.readlane %21, %c63_i32 : (f32, i32) -> f32
  %23 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %23 {
    %24 = vector.broadcast %22 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c64 = arith.constant 64 : index
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = arith.remsi %thread_id_x, %c64 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c64 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = vector.load %1[%workgroup_id_x, %7] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %9 = vector.insert_strided_slice %8, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %10 = arith.addf %9, %cst_0 : vector<1x1x1xf32>
  %11 = vector.extract %10[0, 0, 0] : f32 from vector<1x1x1xf32>
  %12 = arith.addf %11, %cst : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_half_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_mirror(unit) {bound_ctrl = true} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %22 = arith.addf %20, %21 : f32
  %23 = amdgpu.dpp %22 %22  row_bcast_31(unit) {bound_ctrl = true} : f32
  %24 = arith.addf %23, %22 : f32
  %25 = rocdl.readlane %24, %c63_i32 : (f32, i32) -> f32
  %26 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %26 {
    %27 = vector.broadcast %25 : f32 to vector<f32>
    vector.store %27, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c64 = arith.constant 64 : index
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = arith.remsi %thread_id_x, %c64 : index
  %5 = arith.cmpi slt, %4, %c0 : index
  %6 = arith.addi %4, %c64 overflow<nsw> : index
  %7 = arith.select %5, %6, %4 : index
  %8 = vector.load %1[%workgroup_id_x, %7] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %9 = vector.insert_strided_slice %8, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %10 = arith.addf %9, %cst_0 : vector<1x1x1xf32>
  %11 = vector.extract %10[0, 0, 0] : f32 from vector<1x1x1xf32>
  %12 = arith.addf %11, %cst : f32
  %13 = amdgpu.dpp %12 %12  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_half_mirror(unit) {bound_ctrl = true} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_mirror(unit) {bound_ctrl = true} : f32
  %20 = arith.addf %18, %19 : f32
  %21 = amdgpu.dpp %20 %20  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %22 = arith.addf %20, %21 : f32
  %23 = amdgpu.dpp %22 %22  row_bcast_31(unit) {bound_ctrl = true} : f32
  %24 = arith.addf %23, %22 : f32
  %25 = rocdl.readlane %24, %c63_i32 : (f32, i32) -> f32
  %26 = arith.cmpi eq, %thread_id_x, %c0 : index
  scf.if %26 {
    %27 = vector.broadcast %25 : f32 to vector<f32>
    vector.store %27, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After OptimizeIntArithmeticPass (iree-util-optimize-int-arithmetic) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.insert_strided_slice %4, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %6 = arith.addf %5, %cst_0 : vector<1x1x1xf32>
  %7 = vector.extract %6[0, 0, 0] : f32 from vector<1x1x1xf32>
  %8 = arith.addf %7, %cst : f32
  %9 = amdgpu.dpp %8 %8  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %10 = arith.addf %8, %9 : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  row_half_mirror(unit) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_31(unit) {bound_ctrl = true} : f32
  %20 = arith.addf %19, %18 : f32
  %21 = rocdl.readlane %20, %c63_i32 : (f32, i32) -> f32
  %22 = arith.index_castui %thread_id_x : index to i32
  %23 = arith.cmpi eq, %22, %c0_i32 : i32
  scf.if %23 {
    %24 = vector.broadcast %21 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.insert_strided_slice %4, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %6 = arith.addf %5, %cst_0 : vector<1x1x1xf32>
  %7 = vector.extract %6[0, 0, 0] : f32 from vector<1x1x1xf32>
  %8 = arith.addf %7, %cst : f32
  %9 = amdgpu.dpp %8 %8  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %10 = arith.addf %8, %9 : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  row_half_mirror(unit) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_31(unit) {bound_ctrl = true} : f32
  %20 = arith.addf %19, %18 : f32
  %21 = rocdl.readlane %20, %c63_i32 : (f32, i32) -> f32
  %22 = arith.index_castui %thread_id_x : index to i32
  %23 = arith.cmpi eq, %22, %c0_i32 : i32
  scf.if %23 {
    %24 = vector.broadcast %21 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After IREELoopInvariantCodeMotionPass (iree-loop-invariant-code-motion) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<0.000000e+00> : vector<1x1x1xf32>
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.insert_strided_slice %4, %cst_0 {offsets = [0, 0, 0], strides = [1]} : vector<1xf32> into vector<1x1x1xf32>
  %6 = arith.addf %5, %cst_0 : vector<1x1x1xf32>
  %7 = vector.extract %6[0, 0, 0] : f32 from vector<1x1x1xf32>
  %8 = arith.addf %7, %cst : f32
  %9 = amdgpu.dpp %8 %8  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %10 = arith.addf %8, %9 : f32
  %11 = amdgpu.dpp %10 %10  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %12 = arith.addf %10, %11 : f32
  %13 = amdgpu.dpp %12 %12  row_half_mirror(unit) {bound_ctrl = true} : f32
  %14 = arith.addf %12, %13 : f32
  %15 = amdgpu.dpp %14 %14  row_mirror(unit) {bound_ctrl = true} : f32
  %16 = arith.addf %14, %15 : f32
  %17 = amdgpu.dpp %16 %16  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %18 = arith.addf %16, %17 : f32
  %19 = amdgpu.dpp %18 %18  row_bcast_31(unit) {bound_ctrl = true} : f32
  %20 = arith.addf %19, %18 : f32
  %21 = rocdl.readlane %20, %c63_i32 : (f32, i32) -> f32
  %22 = arith.index_castui %thread_id_x : index to i32
  %23 = arith.cmpi eq, %22, %c0_i32 : i32
  scf.if %23 {
    %24 = vector.broadcast %21 : f32 to vector<f32>
    vector.store %24, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After LLVMGPUVectorLoweringPass (iree-llvmgpu-vector-lowering) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After AmdgpuMaskedloadToLoadPass (amdgpu-maskedload-to-load) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After AmdgpuFoldMemRefOpsPass (amdgpu-fold-memrefs-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After GPUCheckResourceUsagePass (iree-codegen-gpu-check-resource-usage) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocationsPass (iree-codegen-hoist-statically-bound-allocations) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After ConvertComplexToStandardPass (convert-complex-to-standard) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After MathTransformPass (iree-codegen-math-transform) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  scf.if %22 {
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  }
  return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After IREECodegenFoldMemRefAliasOpsPass (iree-codegen-fold-memref-alias-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After IREEExpandStridedMetadataPass (iree-codegen-expand-strided-metadata) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1xf32>
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst_0 = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_1 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_1 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = arith.addf %4, %cst : vector<1xf32>
  %6 = vector.extract %5[0] : f32 from vector<1xf32>
  %7 = arith.addf %6, %cst_0 : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After AMDGPUEmulateNarrowTypePass (iree-amdgpu-emulate-narrow-type) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.extract %4[0] : f32 from vector<1xf32>
  %6 = arith.addf %5, %cst : f32
  %7 = arith.addf %6, %cst : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.extract %4[0] : f32 from vector<1xf32>
  %6 = arith.addf %5, %cst : f32
  %7 = arith.addf %6, %cst : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.extract %4[0] : f32 from vector<1xf32>
  %6 = arith.addf %5, %cst : f32
  %7 = arith.addf %6, %cst : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After ConvertUnsupportedFloatArithPass (iree-convert-unsupported-float-arith) //----- //
func.func @reduce_dispatch_0_reduction_8x64_f32() {
  %c0_i32 = arith.constant 0 : i32
  %c63_i32 = arith.constant 63 : i32
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %thread_id_x = gpu.thread_id  x upper_bound 64
  %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
  %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
  %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
  %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
  %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
  %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
  %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
  %5 = vector.extract %4[0] : f32 from vector<1xf32>
  %6 = arith.addf %5, %cst : f32
  %7 = arith.addf %6, %cst : f32
  %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
  %9 = arith.addf %7, %8 : f32
  %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
  %11 = arith.addf %9, %10 : f32
  %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
  %13 = arith.addf %11, %12 : f32
  %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
  %15 = arith.addf %13, %14 : f32
  %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
  %17 = arith.addf %15, %16 : f32
  %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
  %19 = arith.addf %18, %17 : f32
  %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
  %21 = arith.index_castui %thread_id_x : index to i32
  %22 = arith.cmpi eq, %21, %c0_i32 : i32
  cf.cond_br %22, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %23 = vector.broadcast %20 : f32 to vector<f32>
  vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  return
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %c0_i32 = arith.constant 0 : i32
    %c63_i32 = arith.constant 63 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x upper_bound 64
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
    %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
    %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %5 = vector.extract %4[0] : f32 from vector<1xf32>
    %6 = arith.addf %5, %cst : f32
    %7 = arith.addf %6, %cst : f32
    %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
    %9 = arith.addf %7, %8 : f32
    %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
    %11 = arith.addf %9, %10 : f32
    %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
    %13 = arith.addf %11, %12 : f32
    %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
    %15 = arith.addf %13, %14 : f32
    %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
    %17 = arith.addf %15, %16 : f32
    %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
    %19 = arith.addf %18, %17 : f32
    %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
    %21 = arith.index_castui %thread_id_x : index to i32
    %22 = arith.cmpi eq, %21, %c0_i32 : i32
    cf.cond_br %22, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    return
  }
}

// -----// IR Dump After LLVMGPUCastAddressSpaceFunctionPass (iree-llvmgpu-cast-address-space-function) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %c0_i32 = arith.constant 0 : i32
    %c63_i32 = arith.constant 63 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x upper_bound 64
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
    %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
    %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %5 = vector.extract %4[0] : f32 from vector<1xf32>
    %6 = arith.addf %5, %cst : f32
    %7 = arith.addf %6, %cst : f32
    %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
    %9 = arith.addf %7, %8 : f32
    %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
    %11 = arith.addf %9, %10 : f32
    %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
    %13 = arith.addf %11, %12 : f32
    %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
    %15 = arith.addf %13, %14 : f32
    %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
    %17 = arith.addf %15, %16 : f32
    %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
    %19 = arith.addf %18, %17 : f32
    %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
    %21 = arith.index_castui %thread_id_x : index to i32
    %22 = arith.cmpi eq, %21, %c0_i32 : i32
    cf.cond_br %22, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    return
  }
}

// -----// IR Dump After DropCompilerHintsPass (iree-util-drop-compiler-hints) //----- //
module {
  func.func @reduce_dispatch_0_reduction_8x64_f32() {
    %c0_i32 = arith.constant 0 : i32
    %c63_i32 = arith.constant 63 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %thread_id_x = gpu.thread_id  x upper_bound 64
    %0 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(0) alignment(64) offset(%c0) flags("ReadOnly|Indirect") {iree_gpu.use_rocdl_buffer_instructions} : memref<8x64xf32, #gpu.address_space<global>>
    %assume_align = memref.assume_alignment %0, 64 : memref<8x64xf32, #gpu.address_space<global>>
    %1 = amdgpu.fat_raw_buffer_cast %assume_align resetOffset : memref<8x64xf32, #gpu.address_space<global>> to memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>
    %2 = hal.interface.binding.subspan layout(<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) binding(1) alignment(64) offset(%c0) flags(Indirect) {iree_gpu.use_rocdl_buffer_instructions} : memref<8xf32, #gpu.address_space<global>>
    %assume_align_0 = memref.assume_alignment %2, 64 : memref<8xf32, #gpu.address_space<global>>
    %3 = amdgpu.fat_raw_buffer_cast %assume_align_0 resetOffset : memref<8xf32, #gpu.address_space<global>> to memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] upper_bound 8 : index
    %4 = vector.load %1[%workgroup_id_x, %thread_id_x] : memref<8x64xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<1xf32>
    %5 = vector.extract %4[0] : f32 from vector<1xf32>
    %6 = arith.addf %5, %cst : f32
    %7 = arith.addf %6, %cst : f32
    %8 = amdgpu.dpp %7 %7  quad_perm([1 : i32, 0 : i32, 3 : i32, 2 : i32]) {bound_ctrl = true} : f32
    %9 = arith.addf %7, %8 : f32
    %10 = amdgpu.dpp %9 %9  quad_perm([2 : i32, 3 : i32, 0 : i32, 1 : i32]) {bound_ctrl = true} : f32
    %11 = arith.addf %9, %10 : f32
    %12 = amdgpu.dpp %11 %11  row_half_mirror(unit) {bound_ctrl = true} : f32
    %13 = arith.addf %11, %12 : f32
    %14 = amdgpu.dpp %13 %13  row_mirror(unit) {bound_ctrl = true} : f32
    %15 = arith.addf %13, %14 : f32
    %16 = amdgpu.dpp %15 %15  row_bcast_15(unit) {row_mask = 10 : i32} : f32
    %17 = arith.addf %15, %16 : f32
    %18 = amdgpu.dpp %17 %17  row_bcast_31(unit) {bound_ctrl = true} : f32
    %19 = arith.addf %18, %17 : f32
    %20 = rocdl.readlane %19, %c63_i32 : (f32, i32) -> f32
    %21 = arith.index_castui %thread_id_x : index to i32
    %22 = arith.cmpi eq, %21, %c0_i32 : i32
    cf.cond_br %22, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %23 = vector.broadcast %20 : f32 to vector<f32>
    vector.store %23, %3[%workgroup_id_x] : memref<8xf32, #amdgpu.address_space<fat_raw_buffer>>, vector<f32>
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    return
  }
}

// -----// IR Dump After ConvertToROCDLPass (iree-convert-to-rocdl) //----- //
module {
  llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.nonnull, llvm.noundef}) {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.constant(63 : i32) : i32
    %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
    %5 = llvm.sext %4 : i32 to i64
    %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
    %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.mlir.constant(0 : index) : i64
    %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.mlir.constant(8 : index) : i64
    %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.mlir.constant(64 : index) : i64
    %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.mlir.constant(64 : index) : i64
    %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.mlir.constant(1 : index) : i64
    %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.mlir.constant(true) : i1
    %21 = llvm.mlir.constant(64 : index) : i64
    llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
    %22 = llvm.mlir.constant(2048 : i64) : i64
    %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.mlir.constant(0 : index) : i64
    %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.mlir.constant(0 : i16) : i16
    %28 = llvm.mlir.constant(159744 : i32) : i32
    %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
    %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
    %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.mlir.constant(0 : index) : i64
    %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.constant(8 : index) : i64
    %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.mlir.constant(1 : index) : i64
    %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.mlir.constant(true) : i1
    %47 = llvm.mlir.constant(64 : index) : i64
    llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
    %48 = llvm.mlir.constant(32 : i64) : i64
    %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.mlir.constant(0 : index) : i64
    %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.mlir.constant(0 : i16) : i16
    %54 = llvm.mlir.constant(159744 : i32) : i32
    %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
    %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
    %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
    %63 = llvm.sext %62 : i32 to i64
    %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
    %65 = llvm.mlir.constant(64 : index) : i64
    %66 = llvm.mul %63, %65 : i64
    %67 = llvm.add %66, %5 : i64
    %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
    %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
    %70 = llvm.mlir.constant(0 : i64) : i64
    %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
    %72 = llvm.fadd %71, %2 : f32
    %73 = llvm.fadd %72, %2 : f32
    %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
    %75 = llvm.fadd %73, %74 : f32
    %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
    %77 = llvm.fadd %75, %76 : f32
    %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
    %79 = llvm.fadd %77, %78 : f32
    %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
    %81 = llvm.fadd %79, %80 : f32
    %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
    %83 = llvm.fadd %81, %82 : f32
    %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
    %85 = llvm.fadd %84, %83 : f32
    %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
    %87 = llvm.trunc %5 : i64 to i32
    %88 = llvm.icmp "eq" %87, %0 : i32
    llvm.cond_br %88, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %89 = llvm.mlir.poison : vector<1xf32>
    %90 = llvm.mlir.constant(0 : i32) : i32
    %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
    %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
    %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
    llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
    llvm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    llvm.return
  }
}

// -----// IR Dump After ROCDLAnnotateKernelForTranslationPass (iree-rocdl-annotate-kernel-for-translation) //----- //
llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %1 = llvm.mlir.constant(63 : i32) : i32
  %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %3 = llvm.mlir.constant(0 : index) : i64
  %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
  %5 = llvm.sext %4 : i32 to i64
  %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
  %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %9 = llvm.mlir.constant(0 : index) : i64
  %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %11 = llvm.mlir.constant(8 : index) : i64
  %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %13 = llvm.mlir.constant(64 : index) : i64
  %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %15 = llvm.mlir.constant(64 : index) : i64
  %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %17 = llvm.mlir.constant(1 : index) : i64
  %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %20 = llvm.mlir.constant(true) : i1
  %21 = llvm.mlir.constant(64 : index) : i64
  llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
  %22 = llvm.mlir.constant(2048 : i64) : i64
  %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %24 = llvm.mlir.constant(0 : index) : i64
  %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
  %27 = llvm.mlir.constant(0 : i16) : i16
  %28 = llvm.mlir.constant(159744 : i32) : i32
  %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
  %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
  %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
  %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %39 = llvm.mlir.constant(0 : index) : i64
  %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %41 = llvm.mlir.constant(8 : index) : i64
  %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %43 = llvm.mlir.constant(1 : index) : i64
  %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %46 = llvm.mlir.constant(true) : i1
  %47 = llvm.mlir.constant(64 : index) : i64
  llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
  %48 = llvm.mlir.constant(32 : i64) : i64
  %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %50 = llvm.mlir.constant(0 : index) : i64
  %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
  %53 = llvm.mlir.constant(0 : i16) : i16
  %54 = llvm.mlir.constant(159744 : i32) : i32
  %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
  %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
  %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
  %63 = llvm.sext %62 : i32 to i64
  %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
  %65 = llvm.mlir.constant(64 : index) : i64
  %66 = llvm.mul %63, %65 : i64
  %67 = llvm.add %66, %5 : i64
  %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
  %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
  %70 = llvm.mlir.constant(0 : i64) : i64
  %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
  %72 = llvm.fadd %71, %2 : f32
  %73 = llvm.fadd %72, %2 : f32
  %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
  %75 = llvm.fadd %73, %74 : f32
  %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
  %77 = llvm.fadd %75, %76 : f32
  %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
  %79 = llvm.fadd %77, %78 : f32
  %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
  %81 = llvm.fadd %79, %80 : f32
  %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
  %83 = llvm.fadd %81, %82 : f32
  %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
  %85 = llvm.fadd %84, %83 : f32
  %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
  %87 = llvm.trunc %5 : i64 to i32
  %88 = llvm.icmp "eq" %87, %0 : i32
  llvm.cond_br %88, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %89 = llvm.mlir.poison : vector<1xf32>
  %90 = llvm.mlir.constant(0 : i32) : i32
  %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
  %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
  %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
  llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
  llvm.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  llvm.return
}

// -----// IR Dump After TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
    %c8 = arith.constant 8 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    hal.return %c8, %c1, %c1_0 : index, index, index
  } attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
  builtin.module {
    llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
      %0 = llvm.mlir.constant(0 : i32) : i32
      %1 = llvm.mlir.constant(63 : i32) : i32
      %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %3 = llvm.mlir.constant(0 : index) : i64
      %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
      %5 = llvm.sext %4 : i32 to i64
      %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
      %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %9 = llvm.mlir.constant(0 : index) : i64
      %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %11 = llvm.mlir.constant(8 : index) : i64
      %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %13 = llvm.mlir.constant(64 : index) : i64
      %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %15 = llvm.mlir.constant(64 : index) : i64
      %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %17 = llvm.mlir.constant(1 : index) : i64
      %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %20 = llvm.mlir.constant(true) : i1
      %21 = llvm.mlir.constant(64 : index) : i64
      llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
      %22 = llvm.mlir.constant(2048 : i64) : i64
      %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %24 = llvm.mlir.constant(0 : index) : i64
      %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
      %27 = llvm.mlir.constant(0 : i16) : i16
      %28 = llvm.mlir.constant(159744 : i32) : i32
      %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
      %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
      %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
      %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %39 = llvm.mlir.constant(0 : index) : i64
      %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %41 = llvm.mlir.constant(8 : index) : i64
      %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %43 = llvm.mlir.constant(1 : index) : i64
      %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %46 = llvm.mlir.constant(true) : i1
      %47 = llvm.mlir.constant(64 : index) : i64
      llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
      %48 = llvm.mlir.constant(32 : i64) : i64
      %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %50 = llvm.mlir.constant(0 : index) : i64
      %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
      %53 = llvm.mlir.constant(0 : i16) : i16
      %54 = llvm.mlir.constant(159744 : i32) : i32
      %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
      %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
      %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
      %63 = llvm.sext %62 : i32 to i64
      %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
      %65 = llvm.mlir.constant(64 : index) : i64
      %66 = llvm.mul %63, %65 : i64
      %67 = llvm.add %66, %5 : i64
      %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
      %70 = llvm.mlir.constant(0 : i64) : i64
      %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
      %72 = llvm.fadd %71, %2 : f32
      %73 = llvm.fadd %72, %2 : f32
      %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
      %75 = llvm.fadd %73, %74 : f32
      %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
      %77 = llvm.fadd %75, %76 : f32
      %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
      %79 = llvm.fadd %77, %78 : f32
      %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
      %81 = llvm.fadd %79, %80 : f32
      %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
      %83 = llvm.fadd %81, %82 : f32
      %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
      %85 = llvm.fadd %84, %83 : f32
      %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
      %87 = llvm.trunc %5 : i64 to i32
      %88 = llvm.icmp "eq" %87, %0 : i32
      llvm.cond_br %88, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %89 = llvm.mlir.poison : vector<1xf32>
      %90 = llvm.mlir.constant(0 : i32) : i32
      %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
      %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
      %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
      llvm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      llvm.return
    }
  }
}

// -----// IR Dump After TranslateAllExecutablesPass (iree-hal-translate-all-executables) //----- //
hal.executable private @reduce_dispatch_0 {
  hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
    hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) count(%arg0: !hal.device) -> (index, index, index) {
      %c8 = arith.constant 8 : index
      %c1 = arith.constant 1 : index
      %c1_0 = arith.constant 1 : index
      hal.return %c8, %c1, %c1_0 : index, index, index
    } attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
    builtin.module {
      llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
        %0 = llvm.mlir.constant(0 : i32) : i32
        %1 = llvm.mlir.constant(63 : i32) : i32
        %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
        %3 = llvm.mlir.constant(0 : index) : i64
        %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
        %5 = llvm.sext %4 : i32 to i64
        %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
        %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %9 = llvm.mlir.constant(0 : index) : i64
        %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %11 = llvm.mlir.constant(8 : index) : i64
        %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %13 = llvm.mlir.constant(64 : index) : i64
        %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %15 = llvm.mlir.constant(64 : index) : i64
        %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %17 = llvm.mlir.constant(1 : index) : i64
        %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %20 = llvm.mlir.constant(true) : i1
        %21 = llvm.mlir.constant(64 : index) : i64
        llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
        %22 = llvm.mlir.constant(2048 : i64) : i64
        %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %24 = llvm.mlir.constant(0 : index) : i64
        %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
        %27 = llvm.mlir.constant(0 : i16) : i16
        %28 = llvm.mlir.constant(159744 : i32) : i32
        %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
        %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
        %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
        %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %39 = llvm.mlir.constant(0 : index) : i64
        %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %41 = llvm.mlir.constant(8 : index) : i64
        %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %43 = llvm.mlir.constant(1 : index) : i64
        %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.mlir.constant(true) : i1
        %47 = llvm.mlir.constant(64 : index) : i64
        llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
        %48 = llvm.mlir.constant(32 : i64) : i64
        %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.mlir.constant(0 : index) : i64
        %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
        %53 = llvm.mlir.constant(0 : i16) : i16
        %54 = llvm.mlir.constant(159744 : i32) : i32
        %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
        %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
        %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
        %63 = llvm.sext %62 : i32 to i64
        %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
        %65 = llvm.mlir.constant(64 : index) : i64
        %66 = llvm.mul %63, %65 : i64
        %67 = llvm.add %66, %5 : i64
        %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
        %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
        %70 = llvm.mlir.constant(0 : i64) : i64
        %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
        %72 = llvm.fadd %71, %2 : f32
        %73 = llvm.fadd %72, %2 : f32
        %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
        %75 = llvm.fadd %73, %74 : f32
        %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
        %77 = llvm.fadd %75, %76 : f32
        %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
        %79 = llvm.fadd %77, %78 : f32
        %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
        %81 = llvm.fadd %79, %80 : f32
        %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
        %83 = llvm.fadd %81, %82 : f32
        %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
        %85 = llvm.fadd %84, %83 : f32
        %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
        %87 = llvm.trunc %5 : i64 to i32
        %88 = llvm.icmp "eq" %87, %0 : i32
        llvm.cond_br %88, ^bb1, ^bb2
      ^bb1:  // pred: ^bb0
        %89 = llvm.mlir.poison : vector<1xf32>
        %90 = llvm.mlir.constant(0 : i32) : i32
        %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
        %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
        %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
        llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
        llvm.br ^bb2
      ^bb2:  // 2 preds: ^bb0, ^bb1
        llvm.return
      }
    }
  }
}

// -----// IR Dump After ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.constant(0 : i32) : i32
          %1 = llvm.mlir.constant(63 : i32) : i32
          %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %5 = llvm.sext %4 : i32 to i64
          %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
          %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %9 = llvm.mlir.constant(0 : index) : i64
          %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %11 = llvm.mlir.constant(8 : index) : i64
          %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %13 = llvm.mlir.constant(64 : index) : i64
          %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %15 = llvm.mlir.constant(64 : index) : i64
          %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %17 = llvm.mlir.constant(1 : index) : i64
          %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %20 = llvm.mlir.constant(true) : i1
          %21 = llvm.mlir.constant(64 : index) : i64
          llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
          %22 = llvm.mlir.constant(2048 : i64) : i64
          %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %24 = llvm.mlir.constant(0 : index) : i64
          %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %27 = llvm.mlir.constant(0 : i16) : i16
          %28 = llvm.mlir.constant(159744 : i32) : i32
          %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
          %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
          %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
          %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %39 = llvm.mlir.constant(0 : index) : i64
          %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %41 = llvm.mlir.constant(8 : index) : i64
          %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %43 = llvm.mlir.constant(1 : index) : i64
          %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %46 = llvm.mlir.constant(true) : i1
          %47 = llvm.mlir.constant(64 : index) : i64
          llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
          %48 = llvm.mlir.constant(32 : i64) : i64
          %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %50 = llvm.mlir.constant(0 : index) : i64
          %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %53 = llvm.mlir.constant(0 : i16) : i16
          %54 = llvm.mlir.constant(159744 : i32) : i32
          %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
          %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
          %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %63 = llvm.sext %62 : i32 to i64
          %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %65 = llvm.mlir.constant(64 : index) : i64
          %66 = llvm.mul %63, %65 : i64
          %67 = llvm.add %66, %5 : i64
          %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %70 = llvm.mlir.constant(0 : i64) : i64
          %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
          %72 = llvm.fadd %71, %2 : f32
          %73 = llvm.fadd %72, %2 : f32
          %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
          %75 = llvm.fadd %73, %74 : f32
          %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
          %77 = llvm.fadd %75, %76 : f32
          %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
          %79 = llvm.fadd %77, %78 : f32
          %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
          %81 = llvm.fadd %79, %80 : f32
          %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
          %83 = llvm.fadd %81, %82 : f32
          %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
          %85 = llvm.fadd %84, %83 : f32
          %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
          %87 = llvm.trunc %5 : i64 to i32
          %88 = llvm.icmp "eq" %87, %0 : i32
          llvm.cond_br %88, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %89 = llvm.mlir.poison : vector<1xf32>
          %90 = llvm.mlir.constant(0 : i32) : i32
          %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
          %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %__device_0_0 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_2 = arith.constant -1 : i64
    %c0_3 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = hal.device.memoize<%__device_0_1 : !hal.device> affinity(%c-1_i64_2) -> !hal.command_buffer {
      %c2 = arith.constant 2 : index
      %cmd = hal.command_buffer.create device(%__device_0_1 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64_2) bindings(%c2) : !hal.command_buffer
      %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%2 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
      %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
      %c8_9 = arith.constant 8 : index
      %c1_10 = arith.constant 1 : index
      %c1_11 = arith.constant 1 : index
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8_9, %c1_10, %c1_11]) bindings([
        (%c0_3 : index)[%c0, %c2048], 
        (%c1 : index)[%c0, %c32]
      ]) flags("None")
      hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
      hal.command_buffer.finalize<%cmd : !hal.command_buffer>
      hal.return %cmd : !hal.command_buffer
    }
    %fence_4 = hal.fence.create device(%__device_0_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0_1 : !hal.device> affinity(%c-1_i64_2) wait(%fence) signal(%fence_4) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0_3, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0_3, %c32]
    ]) flags("None")
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_5 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_6 = hal.element_type<f32> : i32
    %c8_7 = arith.constant 8 : index
    %c0_8 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_8, %c32] shape([%c8_7]) type(%element_type_f32_6) encoding(%dense_row_major_5) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineMemoizeRegionsPass (iree-hal-outline-memoize-regions) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.constant(0 : i32) : i32
          %1 = llvm.mlir.constant(63 : i32) : i32
          %2 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %5 = llvm.sext %4 : i32 to i64
          %6 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)>
          %7 = llvm.insertvalue %arg0, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %8 = llvm.insertvalue %arg0, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %9 = llvm.mlir.constant(0 : index) : i64
          %10 = llvm.insertvalue %9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %11 = llvm.mlir.constant(8 : index) : i64
          %12 = llvm.insertvalue %11, %10[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %13 = llvm.mlir.constant(64 : index) : i64
          %14 = llvm.insertvalue %13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %15 = llvm.mlir.constant(64 : index) : i64
          %16 = llvm.insertvalue %15, %14[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %17 = llvm.mlir.constant(1 : index) : i64
          %18 = llvm.insertvalue %17, %16[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %19 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %20 = llvm.mlir.constant(true) : i1
          %21 = llvm.mlir.constant(64 : index) : i64
          llvm.intr.assume %20 ["align"(%19, %21 : !llvm.ptr<1>, i64)] : i1
          %22 = llvm.mlir.constant(2048 : i64) : i64
          %23 = llvm.extractvalue %18[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %24 = llvm.mlir.constant(0 : index) : i64
          %25 = llvm.extractvalue %18[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %26 = llvm.extractvalue %18[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<2 x i64>, array<2 x i64>)> 
          %27 = llvm.mlir.constant(0 : i16) : i16
          %28 = llvm.mlir.constant(159744 : i32) : i32
          %29 = rocdl.make.buffer.rsrc %23, %27, %22, %28 : <1> to <7>
          %30 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)>
          %31 = llvm.insertvalue %29, %30[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %32 = llvm.insertvalue %29, %31[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %33 = llvm.insertvalue %24, %32[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %34 = llvm.insertvalue %25, %33[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %35 = llvm.insertvalue %26, %34[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %36 = llvm.mlir.poison : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)>
          %37 = llvm.insertvalue %arg1, %36[0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %38 = llvm.insertvalue %arg1, %37[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %39 = llvm.mlir.constant(0 : index) : i64
          %40 = llvm.insertvalue %39, %38[2] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %41 = llvm.mlir.constant(8 : index) : i64
          %42 = llvm.insertvalue %41, %40[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %43 = llvm.mlir.constant(1 : index) : i64
          %44 = llvm.insertvalue %43, %42[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %45 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %46 = llvm.mlir.constant(true) : i1
          %47 = llvm.mlir.constant(64 : index) : i64
          llvm.intr.assume %46 ["align"(%45, %47 : !llvm.ptr<1>, i64)] : i1
          %48 = llvm.mlir.constant(32 : i64) : i64
          %49 = llvm.extractvalue %44[1] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %50 = llvm.mlir.constant(0 : index) : i64
          %51 = llvm.extractvalue %44[3] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %52 = llvm.extractvalue %44[4] : !llvm.struct<(ptr<1>, ptr<1>, i64, array<1 x i64>, array<1 x i64>)> 
          %53 = llvm.mlir.constant(0 : i16) : i16
          %54 = llvm.mlir.constant(159744 : i32) : i32
          %55 = rocdl.make.buffer.rsrc %49, %53, %48, %54 : <1> to <7>
          %56 = llvm.mlir.poison : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)>
          %57 = llvm.insertvalue %55, %56[0] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %58 = llvm.insertvalue %55, %57[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %59 = llvm.insertvalue %50, %58[2] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %60 = llvm.insertvalue %51, %59[3] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.insertvalue %52, %60[4] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %62 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %63 = llvm.sext %62 : i32 to i64
          %64 = llvm.extractvalue %35[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<2 x i64>, array<2 x i64>)> 
          %65 = llvm.mlir.constant(64 : index) : i64
          %66 = llvm.mul %63, %65 : i64
          %67 = llvm.add %66, %5 : i64
          %68 = llvm.getelementptr %64[%67] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %69 = llvm.load %68 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %70 = llvm.mlir.constant(0 : i64) : i64
          %71 = llvm.extractelement %69[%70 : i64] : vector<1xf32>
          %72 = llvm.fadd %71, %2 : f32
          %73 = llvm.fadd %72, %2 : f32
          %74 = rocdl.update.dpp %73, %73 with 177, 15, 15, true : f32
          %75 = llvm.fadd %73, %74 : f32
          %76 = rocdl.update.dpp %75, %75 with 78, 15, 15, true : f32
          %77 = llvm.fadd %75, %76 : f32
          %78 = rocdl.update.dpp %77, %77 with 321, 15, 15, true : f32
          %79 = llvm.fadd %77, %78 : f32
          %80 = rocdl.update.dpp %79, %79 with 320, 15, 15, true : f32
          %81 = llvm.fadd %79, %80 : f32
          %82 = rocdl.update.dpp %81, %81 with 322, 10, 15, false : f32
          %83 = llvm.fadd %81, %82 : f32
          %84 = rocdl.update.dpp %83, %83 with 323, 15, 15, true : f32
          %85 = llvm.fadd %84, %83 : f32
          %86 = rocdl.readlane %85, %1 : (f32, i32) -> f32
          %87 = llvm.trunc %5 : i64 to i32
          %88 = llvm.icmp "eq" %87, %0 : i32
          llvm.cond_br %88, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %89 = llvm.mlir.poison : vector<1xf32>
          %90 = llvm.mlir.constant(0 : i32) : i32
          %91 = llvm.insertelement %86, %89[%90 : i32] : vector<1xf32>
          %92 = llvm.extractvalue %61[1] : !llvm.struct<(ptr<7>, ptr<7>, i64, array<1 x i64>, array<1 x i64>)> 
          %93 = llvm.getelementptr %92[%63] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %91, %93 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c2 = arith.constant 2 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %exe = hal.executable.lookup device(%0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    %c8 = arith.constant 8 : index
    %c1_1 = arith.constant 1 : index
    %c1_2 = arith.constant 1 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1_1, %c1_2]) bindings([
      (%c0 : index)[%c0_0, %c2048], 
      (%c1 : index)[%c0_0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %0 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %1 = scf.if %0 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      %2 = util.null : !hal.command_buffer
      scf.yield %2 : !hal.command_buffer
    }
    util.return %1 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %__device_0_0 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%__device_0_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%__device_0_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64_2 = arith.constant -1 : i64
    %c0_3 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.call @__reduce_memoize_lookup(%__device_0_1, %c-1_i64_2) : (!hal.device, i64) -> !hal.command_buffer
    %fence_4 = hal.fence.create device(%__device_0_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0_1 : !hal.device> affinity(%c-1_i64_2) wait(%fence) signal(%fence_4) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0_3, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0_3, %c32]
    ]) flags("None")
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %dense_row_major_5 = hal.encoding_type<dense_row_major> : i32
    %element_type_f32_6 = hal.element_type<f32> : i32
    %c8_7 = arith.constant 8 : index
    %c0_8 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_8, %c32] shape([%c8_7]) type(%element_type_f32_6) encoding(%dense_row_major_5) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
  %__device_0_0 = util.global.load immutable @__device_0 : !hal.device
  %fence = hal.fence.create device(%__device_0_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %__device_0_1 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.call @__reduce_memoize_lookup(%__device_0_1, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_2 = hal.fence.create device(%__device_0_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0_1 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_2) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_2]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %dense_row_major_3 = hal.encoding_type<dense_row_major> : i32
  %element_type_f32_4 = hal.element_type<f32> : i32
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32_4) encoding(%dense_row_major_3) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %0 = util.null : !hal.command_buffer
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
  %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After LLVMGPULinkExecutablesPass (iree-llvmgpu-link-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
hal.executable private @reduce_dispatch_0 {
  hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
    hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
    builtin.module {
      llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
        %0 = llvm.mlir.poison : vector<1xf32>
        %1 = llvm.mlir.constant(0 : i64) : i64
        %2 = llvm.mlir.constant(32 : i64) : i64
        %3 = llvm.mlir.constant(159744 : i32) : i32
        %4 = llvm.mlir.constant(0 : i16) : i16
        %5 = llvm.mlir.constant(2048 : i64) : i64
        %6 = llvm.mlir.constant(true) : i1
        %7 = llvm.mlir.constant(64 : index) : i64
        %8 = llvm.mlir.constant(0 : i32) : i32
        %9 = llvm.mlir.constant(63 : i32) : i32
        %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
        %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
        %12 = llvm.sext %11 : i32 to i64
        llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
        %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
        llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
        %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
        %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
        %16 = llvm.sext %15 : i32 to i64
        %17 = llvm.mul %16, %7 : i64
        %18 = llvm.add %17, %12 : i64
        %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
        %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
        %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
        %22 = llvm.fadd %21, %10 : f32
        %23 = llvm.fadd %22, %10 : f32
        %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
        %25 = llvm.fadd %23, %24 : f32
        %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
        %27 = llvm.fadd %25, %26 : f32
        %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
        %29 = llvm.fadd %27, %28 : f32
        %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
        %31 = llvm.fadd %29, %30 : f32
        %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
        %33 = llvm.fadd %31, %32 : f32
        %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
        %35 = llvm.fadd %34, %33 : f32
        %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
        %37 = llvm.trunc %12 : i64 to i32
        %38 = llvm.icmp "eq" %37, %8 : i32
        llvm.cond_br %38, ^bb1, ^bb2
      ^bb1:  // pred: ^bb0
        %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
        %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
        llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
        llvm.br ^bb2
      ^bb2:  // 2 preds: ^bb0, ^bb1
        llvm.return
      }
    }
  }
}

// -----// IR Dump After LLVMGPUAssignConstantOrdinalsPass (iree-llvmgpu-assign-constant-ordinals) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
  builtin.module {
    llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
      %0 = llvm.mlir.poison : vector<1xf32>
      %1 = llvm.mlir.constant(0 : i64) : i64
      %2 = llvm.mlir.constant(32 : i64) : i64
      %3 = llvm.mlir.constant(159744 : i32) : i32
      %4 = llvm.mlir.constant(0 : i16) : i16
      %5 = llvm.mlir.constant(2048 : i64) : i64
      %6 = llvm.mlir.constant(true) : i1
      %7 = llvm.mlir.constant(64 : index) : i64
      %8 = llvm.mlir.constant(0 : i32) : i32
      %9 = llvm.mlir.constant(63 : i32) : i32
      %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
      %12 = llvm.sext %11 : i32 to i64
      llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
      %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
      llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
      %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
      %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
      %16 = llvm.sext %15 : i32 to i64
      %17 = llvm.mul %16, %7 : i64
      %18 = llvm.add %17, %12 : i64
      %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
      %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
      %22 = llvm.fadd %21, %10 : f32
      %23 = llvm.fadd %22, %10 : f32
      %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
      %25 = llvm.fadd %23, %24 : f32
      %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
      %27 = llvm.fadd %25, %26 : f32
      %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
      %29 = llvm.fadd %27, %28 : f32
      %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
      %31 = llvm.fadd %29, %30 : f32
      %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
      %33 = llvm.fadd %31, %32 : f32
      %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
      %35 = llvm.fadd %34, %33 : f32
      %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
      %37 = llvm.trunc %12 : i64 to i32
      %38 = llvm.icmp "eq" %37, %8 : i32
      llvm.cond_br %38, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
      %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
      llvm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      llvm.return
    }
  }
}

// -----// IR Dump After LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After LinkAllExecutablesPass (iree-hal-link-all-executables) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %ordinal = hal.executable.export.ordinal target(@reduce_dispatch_0::@rocm_hsaco_fb::@reduce_dispatch_0_reduction_8x64_f32) : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%ordinal] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After HoistExecutableObjectsPass (iree-hal-hoist-executable-objects) //----- //
hal.executable.variant public @rocm_hsaco_fb target(<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>) {
  hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
  builtin.module {
    llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
      %0 = llvm.mlir.poison : vector<1xf32>
      %1 = llvm.mlir.constant(0 : i64) : i64
      %2 = llvm.mlir.constant(32 : i64) : i64
      %3 = llvm.mlir.constant(159744 : i32) : i32
      %4 = llvm.mlir.constant(0 : i16) : i16
      %5 = llvm.mlir.constant(2048 : i64) : i64
      %6 = llvm.mlir.constant(true) : i1
      %7 = llvm.mlir.constant(64 : index) : i64
      %8 = llvm.mlir.constant(0 : i32) : i32
      %9 = llvm.mlir.constant(63 : i32) : i32
      %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
      %12 = llvm.sext %11 : i32 to i64
      llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
      %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
      llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
      %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
      %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
      %16 = llvm.sext %15 : i32 to i64
      %17 = llvm.mul %16, %7 : i64
      %18 = llvm.add %17, %12 : i64
      %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
      %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
      %22 = llvm.fadd %21, %10 : f32
      %23 = llvm.fadd %22, %10 : f32
      %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
      %25 = llvm.fadd %23, %24 : f32
      %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
      %27 = llvm.fadd %25, %26 : f32
      %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
      %29 = llvm.fadd %27, %28 : f32
      %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
      %31 = llvm.fadd %29, %30 : f32
      %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
      %33 = llvm.fadd %31, %32 : f32
      %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
      %35 = llvm.fadd %34, %33 : f32
      %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
      %37 = llvm.trunc %12 : i64 to i32
      %38 = llvm.icmp "eq" %37, %8 : i32
      llvm.cond_br %38, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
      %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
      llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
      llvm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      llvm.return
    }
  }
}

// -----// IR Dump After ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %exe = hal.executable.lookup device(%arg0 : !hal.device) executable(@reduce_dispatch_0) : !hal.executable
    %c0_0 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[%c0_0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %c0_0 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0_0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_types, %buffer_usage = hal.allocator.resolve_memory_properties for(#hal.device.affinity<@__device_0>) lifetime(external) : i32, i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_types) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveTopologyQueriesPass (iree-hal-resolve-topology-queries) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %c0_0 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0_0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After MemoizeDeviceSelectionPass (iree-hal-memoize-device-selection) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %c0_0 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0_0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %ok, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    }
    default {
      %c14_i32 = arith.constant 14 : i32
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %c0_0 = arith.constant 0 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0_0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %ok, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load @__device_0 : !hal.device
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %ok, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global.store %ok, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load @__device_0 : !hal.device
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = scf.index_switch %1 -> !hal.executable 
  case 0 {
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  }
  default {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %2, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global.store %ok, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb_ok : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.null : !hal.command_buffer
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %3 = scf.if %2 -> (!hal.executable) {
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  } else {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
#device_target_hip = #hal.device.target<"hip", [#executable_target_rocm_hsaco_fb]> : !hal.device
module {
  util.global private @__device_0 = #device_target_hip
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = scf.if %1 -> (!hal.command_buffer) {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  } else {
    scf.yield %0 : !hal.command_buffer
  }
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %3 = scf.if %2 -> (!hal.executable) {
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    scf.yield %executable : !hal.executable
  } else {
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    scf.yield %0 : !hal.executable
  }
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After InitializeDevicesPass (iree-hal-initialize-devices) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %4 = util.cmp.eq %arg2, %0 : !hal.device
      %5 = arith.cmpi slt, %arg0, %device_count : index
      %6 = arith.andi %4, %5 : i1
      scf.condition(%6) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
      %4 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        %false = arith.constant false
        scf.yield %false : i1
      }
      %5 = arith.cmpi eq, %arg1, %c0 : index
      %6 = arith.select %4, %c1, %c0 : index
      %7 = arith.addi %arg1, %6 : index
      %8 = arith.andi %4, %5 : i1
      %9 = arith.select %8, %device_n, %0 : !hal.device
      %10 = arith.addi %arg0, %c1 : index
      scf.yield %10, %7, %9 : index, index, !hal.device
    }
    %2 = util.null : !hal.device
    %3 = util.cmp.eq %1#2, %2 : !hal.device
    scf.if %3 {
      %c18_i32 = arith.constant 18 : i32
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %3 = util.cmp.eq %arg2, %0 : !hal.device
      %4 = arith.cmpi slt, %arg0, %device_count : index
      %5 = arith.andi %3, %4 : i1
      scf.condition(%5) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
      %3 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        scf.yield %false : i1
      }
      %4 = arith.cmpi eq, %arg1, %c0 : index
      %5 = arith.select %3, %c1, %c0 : index
      %6 = arith.addi %arg1, %5 : index
      %7 = arith.andi %3, %4 : i1
      %8 = arith.select %7, %device_n, %0 : !hal.device
      %9 = arith.addi %arg0, %c1 : index
      scf.yield %9, %6, %8 : index, index, !hal.device
    }
    %2 = util.cmp.eq %1#2, %0 : !hal.device
    scf.if %2 {
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
#executable_target_rocm_hsaco_fb = #hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>
#pipeline_layout = #hal.pipeline.layout<bindings = [#hal.pipeline.binding<storage_buffer, "ReadOnly|Indirect">, #hal.pipeline.binding<storage_buffer, Indirect>], flags = Indirect>
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    %1:3 = scf.while (%arg0 = %c0, %arg1 = %c0, %arg2 = %0) : (index, index, !hal.device) -> (index, index, !hal.device) {
      %3 = util.cmp.eq %arg2, %0 : !hal.device
      %4 = arith.cmpi slt, %arg0, %device_count : index
      %5 = arith.andi %3, %4 : i1
      scf.condition(%5) %arg0, %arg1, %arg2 : index, index, !hal.device
    } do {
    ^bb0(%arg0: index, %arg1: index, %arg2: !hal.device):
      %device_n = hal.devices.get %arg0 : !hal.device
      %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
      %3 = scf.if %value -> (i1) {
        %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
        scf.yield %value_1 : i1
      } else {
        scf.yield %false : i1
      }
      %4 = arith.cmpi eq, %arg1, %c0 : index
      %5 = arith.select %3, %c1, %c0 : index
      %6 = arith.addi %arg1, %5 : index
      %7 = arith.andi %3, %4 : i1
      %8 = arith.select %7, %device_n, %0 : !hal.device
      %9 = arith.addi %arg0, %c1 : index
      scf.yield %9, %6, %8 : index, index, !hal.device
    }
    %2 = util.cmp.eq %1#2, %0 : !hal.device
    scf.if %2 {
      util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    }
    util.global.store %1#2, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    %3 = scf.if %2 -> (!hal.executable) {
      %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
      scf.yield %executable : !hal.executable
    } else {
      util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      scf.yield %0 : !hal.executable
    }
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.variant public @rocm_hsaco_fb target(#executable_target_rocm_hsaco_fb) {
      hal.executable.export public @reduce_dispatch_0_reduction_8x64_f32 ordinal(0) layout(#pipeline_layout) attributes {subgroup_size = 64 : index, workgroup_size = [64 : index, 1 : index, 1 : index]}
      builtin.module {
        llvm.func @reduce_dispatch_0_reduction_8x64_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.inreg, llvm.noalias, llvm.nonnull, llvm.noundef}) attributes {rocdl.flat_work_group_size = "64,64", rocdl.kernel, rocdl.reqd_work_group_size = array<i32: 64, 1, 1>} {
          %0 = llvm.mlir.poison : vector<1xf32>
          %1 = llvm.mlir.constant(0 : i64) : i64
          %2 = llvm.mlir.constant(32 : i64) : i64
          %3 = llvm.mlir.constant(159744 : i32) : i32
          %4 = llvm.mlir.constant(0 : i16) : i16
          %5 = llvm.mlir.constant(2048 : i64) : i64
          %6 = llvm.mlir.constant(true) : i1
          %7 = llvm.mlir.constant(64 : index) : i64
          %8 = llvm.mlir.constant(0 : i32) : i32
          %9 = llvm.mlir.constant(63 : i32) : i32
          %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %11 = rocdl.workitem.id.x range <i32, 0, 64> : i32
          %12 = llvm.sext %11 : i32 to i64
          llvm.intr.assume %6 ["align"(%arg0, %7 : !llvm.ptr<1>, i64)] : i1
          %13 = rocdl.make.buffer.rsrc %arg0, %4, %5, %3 : <1> to <7>
          llvm.intr.assume %6 ["align"(%arg1, %7 : !llvm.ptr<1>, i64)] : i1
          %14 = rocdl.make.buffer.rsrc %arg1, %4, %2, %3 : <1> to <7>
          %15 = rocdl.workgroup.id.x range <i32, 0, 8> : i32
          %16 = llvm.sext %15 : i32 to i64
          %17 = llvm.mul %16, %7 : i64
          %18 = llvm.add %17, %12 : i64
          %19 = llvm.getelementptr %13[%18] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          %20 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr<7> -> vector<1xf32>
          %21 = llvm.extractelement %20[%1 : i64] : vector<1xf32>
          %22 = llvm.fadd %21, %10 : f32
          %23 = llvm.fadd %22, %10 : f32
          %24 = rocdl.update.dpp %23, %23 with 177, 15, 15, true : f32
          %25 = llvm.fadd %23, %24 : f32
          %26 = rocdl.update.dpp %25, %25 with 78, 15, 15, true : f32
          %27 = llvm.fadd %25, %26 : f32
          %28 = rocdl.update.dpp %27, %27 with 321, 15, 15, true : f32
          %29 = llvm.fadd %27, %28 : f32
          %30 = rocdl.update.dpp %29, %29 with 320, 15, 15, true : f32
          %31 = llvm.fadd %29, %30 : f32
          %32 = rocdl.update.dpp %31, %31 with 322, 10, 15, false : f32
          %33 = llvm.fadd %31, %32 : f32
          %34 = rocdl.update.dpp %33, %33 with 323, 15, 15, true : f32
          %35 = llvm.fadd %34, %33 : f32
          %36 = rocdl.readlane %35, %9 : (f32, i32) -> f32
          %37 = llvm.trunc %12 : i64 to i32
          %38 = llvm.icmp "eq" %37, %8 : i32
          llvm.cond_br %38, ^bb1, ^bb2
        ^bb1:  // pred: ^bb0
          %39 = llvm.insertelement %36, %0[%8 : i32] : vector<1xf32>
          %40 = llvm.getelementptr %14[%16] : (!llvm.ptr<7>, i64) -> !llvm.ptr<7>, f32
          llvm.store %39, %40 {alignment = 4 : i64} : vector<1xf32>, !llvm.ptr<7>
          llvm.br ^bb2
        ^bb2:  // 2 preds: ^bb0, ^bb1
          llvm.return
        }
      }
    }
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = scf.if %1 -> (!hal.command_buffer) {
      %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
      scf.yield %__reduce_memoize_result_0_device_0 : !hal.command_buffer
    } else {
      scf.yield %0 : !hal.command_buffer
    }
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  cf.br ^bb4
^bb4:  // pred: ^bb3
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  cf.cond_br %1, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  cf.br ^bb3(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
^bb2:  // pred: ^bb0
  cf.br ^bb3(%0 : !hal.command_buffer)
^bb3(%2: !hal.command_buffer):  // 2 preds: ^bb1, ^bb2
  cf.br ^bb4
^bb4:  // pred: ^bb3
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb5(%value_1 : i1)
^bb4:  // pred: ^bb2
  cf.br ^bb5(%false : i1)
^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
  cf.br ^bb6
^bb6:  // pred: ^bb5
  %11 = arith.cmpi eq, %8, %c0 : index
  %12 = arith.select %10, %c1, %c0 : index
  %13 = arith.addi %8, %12 : index
  %14 = arith.andi %10, %11 : i1
  %15 = arith.select %14, %device_n, %0 : !hal.device
  %16 = arith.addi %7, %c1 : index
  cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
^bb7:  // pred: ^bb1
  %17 = util.cmp.eq %3, %0 : !hal.device
  cf.cond_br %17, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb9
^bb9:  // 2 preds: ^bb7, ^bb8
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @reduce_dispatch_0 {
  hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After SerializeAllExecutablesPass (iree-hal-serialize-all-executables) //----- //
hal.executable private @reduce_dispatch_0 {
  hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After PruneExecutablesPass (iree-hal-prune-executables) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
  ^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
    %device_n = hal.devices.get %7 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb5(%value_1 : i1)
  ^bb4:  // pred: ^bb2
    cf.br ^bb5(%false : i1)
  ^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb6
  ^bb6:  // pred: ^bb5
    %11 = arith.cmpi eq, %8, %c0 : index
    %12 = arith.select %10, %c1, %c0 : index
    %13 = arith.addi %8, %12 : index
    %14 = arith.andi %10, %11 : i1
    %15 = arith.select %14, %device_n, %0 : !hal.device
    %16 = arith.addi %7, %c1 : index
    cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
  ^bb7:  // pred: ^bb1
    %17 = util.cmp.eq %3, %0 : !hal.device
    cf.cond_br %17, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    cf.cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    cf.br ^bb3(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3(%0 : !hal.command_buffer)
  ^bb3(%2: !hal.command_buffer):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb6
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2(%1, %2, %3 : index, index, !hal.device), ^bb7
  ^bb2(%7: index, %8: index, %9: !hal.device):  // pred: ^bb1
    %device_n = hal.devices.get %7 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb5(%value_1 : i1)
  ^bb4:  // pred: ^bb2
    cf.br ^bb5(%false : i1)
  ^bb5(%10: i1):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb6
  ^bb6:  // pred: ^bb5
    %11 = arith.cmpi eq, %8, %c0 : index
    %12 = arith.select %10, %c1, %c0 : index
    %13 = arith.addi %8, %12 : index
    %14 = arith.andi %10, %11 : i1
    %15 = arith.select %14, %device_n, %0 : !hal.device
    %16 = arith.addi %7, %c1 : index
    cf.br ^bb1(%16, %13, %15 : index, index, !hal.device)
  ^bb7:  // pred: ^bb1
    %17 = util.cmp.eq %3, %0 : !hal.device
    cf.cond_br %17, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    cf.cond_br %1, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    cf.br ^bb3(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3(%0 : !hal.command_buffer)
  ^bb3(%2: !hal.command_buffer):  // 2 preds: ^bb1, ^bb2
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  %16 = util.cmp.eq %3, %0 : !hal.device
  cf.cond_br %16, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  cf.cond_br %1, ^bb1, ^bb2(%0 : !hal.command_buffer)
^bb1:  // pred: ^bb0
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  cf.br ^bb2(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
^bb2(%2: !hal.command_buffer):  // 2 preds: ^bb0, ^bb1
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  cf.cond_br %1, ^bb1, ^bb2(%0 : !hal.command_buffer)
^bb1:  // pred: ^bb0
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  cf.br ^bb2(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
^bb2(%2: !hal.command_buffer):  // 2 preds: ^bb0, ^bb1
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2(%1, %2 : index, index), ^bb5
^bb2(%7: index, %8: index):  // pred: ^bb1
  %device_n = hal.devices.get %7 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%9: i1):  // 2 preds: ^bb2, ^bb3
  %10 = arith.cmpi eq, %8, %c0 : index
  %11 = arith.select %9, %c1, %c0 : index
  %12 = arith.addi %8, %11 : index
  %13 = arith.andi %9, %10 : i1
  %14 = arith.select %13, %device_n, %0 : !hal.device
  %15 = arith.addi %7, %c1 : index
  cf.br ^bb1(%15, %12, %14 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %0 = util.null : !hal.command_buffer
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  cf.cond_br %1, ^bb1, ^bb2(%0 : !hal.command_buffer)
^bb1:  // pred: ^bb0
  cf.br ^bb2(%__reduce_memoize_result_0_device_0 : !hal.command_buffer)
^bb2(%2: !hal.command_buffer):  // 2 preds: ^bb0, ^bb1
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
  %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%arg0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%arg1) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup(%arg0: !hal.device, %arg1: i64) -> !hal.command_buffer {
    %0 = util.null : !hal.command_buffer
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %1 = util.cmp.eq %arg0, %__device_0 : !hal.device
    %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup(%__device_0, %c-1_i64) : (!hal.device, i64) -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %0 = util.null : !hal.command_buffer
    %__device_0_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %1 = util.cmp.eq %__device_0, %__device_0_0 : !hal.device
    %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
    util.return %2 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %1 = util.cmp.eq %__device_0, %__device_0_0 : !hal.device
  %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
  %0 = util.null : !hal.command_buffer
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %1 = util.cmp.eq %__device_0, %__device_0 : !hal.device
  %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %0 = util.null : !hal.command_buffer
  %1 = util.cmp.eq %__device_0, %__device_0 : !hal.device
  %2 = arith.select %1, %__reduce_memoize_result_0_device_0, %0 : !hal.command_buffer
  util.return %2 : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return %__reduce_memoize_result_0_device_0 : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 1 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 1 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() -> !hal.command_buffer {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return %__reduce_memoize_result_0_device_0 : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %1 = util.call @__reduce_memoize_lookup() : () -> !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%1) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 1 : index, iree.fixedpoint.modified} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"0x4849503100000000E0140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C000000484950310000000046EBFFFF08000000C4000000010000000400000052EBFFFF300000004000000001000000010000000800000048000000020000000300000000000000020000000000000000000000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000BAEBFFFF2800000004000000C6EBFFFF08000000040000000E000000726564756374696F6E2E6D6C69720000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000010000000400000020ECFFFF04000000D01300007F454C460201014003000000000000000300E000010000000000000000000000400000000000000010100000000000004C05000040003800080040000F000D000600000004000000400000000000000040000000000000004000000000000000C001000000000000C0010000000000000800000000000000010000000400000000000000000000000000000000000000000000000000000000060000000000000006000000000000001000000000000001000000050000000006000000000000001600000000000000160000000000000006000000000000000600000000000000100000000000000100000006000000000C000000000000002C000000000000002C0000000000007000000000000000000400000000000000100000000000000200000006000000000C000000000000002C000000000000002C00000000000070000000000000007000000000000000080000000000000052E5746404000000000C000000000000002C000000000000002C00000000000070000000000000000004000000000000010000000000000051E57464060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000004000000000200000000000000020000000000000002000000000000A402000000000000A4020000000000000400000000000000070000008E02000020000000414D44475055000083AE616D646873612E6B65726E656C7391DE0011AB2E616770725F636F756E7400A52E617267739285AE2E61637475616C5F616363657373A9726561645F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657400A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F62756666657285AE2E61637475616C5F616363657373AA77726974655F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657408A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F627566666572B92E67726F75705F7365676D656E745F66697865645F73697A6500B62E6B65726E6172675F7365676D656E745F616C69676E08B52E6B65726E6172675F7365676D656E745F73697A6510B82E6D61785F666C61745F776F726B67726F75705F73697A6540A52E6E616D65D9247265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332BB2E707269766174655F7365676D656E745F66697865645F73697A6500B42E726571645F776F726B67726F75705F73697A6593400101AB2E736770725F636F756E7412B12E736770725F7370696C6C5F636F756E7400A72E73796D626F6CD9277265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64B82E756E69666F726D5F776F726B5F67726F75705F73697A6501B32E757365735F64796E616D69635F737461636BC2AB2E766770725F636F756E7403B12E766770725F7370696C6C5F636F756E7400AF2E7761766566726F6E745F73697A6540AD616D646873612E746172676574B9616D6467636E2D616D642D616D646873612D2D676678393432AE616D646873612E76657273696F6E92010200000000000000000000000000000000000000000000000000000000000001000000120307000016000000000000C8010000000000002600000011000600C00500000000000040000000000000000100000001000000010000001A000000800004000404000001000000EAD60688873820480300000003000000010000000000000002000000000000000000000000000000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B640000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000040100000000000000000000000000000000000000000000000000000000000008000AF008C0000000800040000000000800006C000000000000106C0080000007FC08CBF3A0082BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF060080BE020188BE8200022409FF0986FFFF0000FF008BBE0070020000080AB0010000D200100504001050E0010102808000947D700F8CBF80020202010080BFFA02020201B108FF010080BFFA020202014E08FF010080BFFA020202014109FF010080BFFA020202014009FF0103047E010080BFFA02047E024201AF02030202010080BFFA020202014309FF000080BF010089D2017F01006A2082BE090088BF0082008E05FF0586FFFF0000A00086BE0B0087BE0102027E0002007E001070E000010180000081BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF0600000000000000A8040000000000000B000000000000001800000000000000050000000000000034050000000000000A000000000000004E00000000000000F5FEFF6F00000000F00400000000000004000000000000001405000000000000000000000000000000000000000000004952454500000000000000000000000000000000000000000000000000000000010000000000F1FF00000000000000000000000000000000370000000000F1FF03000000000000000000000000000000650000000000F1FF00000000000000000000000000000000930000000000F1FF0C000000000000000000000000000000C60000000000F1FF01000000000000000000000000000000F40000000000F1FF000000000000000000000000000000002B0100000000F1FF00000000000000000000000000000000640100000000F1FF00000000000000000000000000000000E401000000020800002C000000000000000000000000000097010000120307000016000000000000C801000000000000BC01000011000600C0050000000000004000000000000000002E6E6F7465002E64796E73796D002E676E752E68617368002E68617368002E64796E737472002E726F64617461002E74657874002E64796E616D6963002E72656C726F5F70616464696E67002E414D444750552E6770725F6D6178696D756D73002E636F6D6D656E74002E73796D746162002E7368737472746162002E73747274616200007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E707269766174655F7365675F73697A65007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F76677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F61677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D62657265645F73677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F766363007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F666C61745F73637261746368007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F64796E5F73697A65645F737461636B007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F726563757273696F6E007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64005F44594E414D494300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000007000000020000000000000000020000000000000002000000000000A402000000000000000000000000000004000000000000000000000000000000070000000B0000000200000000000000A804000000000000A80400000000000048000000000000000500000001000000080000000000000018000000000000000F000000F6FFFF6F0200000000000000F004000000000000F0040000000000002400000000000000020000000000000008000000000000000000000000000000190000000500000002000000000000001405000000000000140500000000000020000000000000000200000000000000040000000000000004000000000000001F000000030000000200000000000000340500000000000034050000000000004E0000000000000000000000000000000100000000000000000000000000000027000000010000000200000000000000C005000000000000C00500000000000040000000000000000000000000000000400000000000000000000000000000002F00000001000000060000000000000000160000000000000006000000000000000600000000000000000000000000000001000000000000000000000000000035000000060000000300000000000000002C000000000000000C00000000000070000000000000000500000000000000080000000000000010000000000000003E000000080000000300000000000000702C000000000000700C00000000000090030000000000000000000000000000010000000000000000000000000000004D0000000100000000000000000000000000000000000000700C0000000000000000000000000000000000000000000001000000000000000000000000000000620000000100000030000000000000000000000000000000700C00000000000005000000000000000000000000000000010000000000000001000000000000006B0000000200000000000000000000000000000000000000780C00000000000020010000000000000E0000000A00000008000000000000001800000000000000730000000300000000000000000000000000000000000000980D00000000000085000000000000000000000000000000010000000000000000000000000000007D00000003000000000000000000000000000000000000001D0E000000000000ED010000000000000000000000000000010000000000000000000000000000000000000006000800040008000C000400080012001C000000040008000000000014001800"> : vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() {
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    util.call @__reduce_memoize_lookup() : () -> ()
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_lookup() {
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_lookup() {
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_lookup() {
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  util.call @__reduce_memoize_lookup() : () -> ()
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_lookup() {
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  util.call @__reduce_memoize_lookup() : () -> ()
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  util.call @__reduce_memoize_lookup() : () -> ()
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  util.call @__reduce_memoize_lookup() : () -> ()
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 2 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() {
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    util.call @__reduce_memoize_lookup() : () -> ()
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 2 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func private @__reduce_memoize_lookup() {
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    util.call @__reduce_memoize_lookup() : () -> ()
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 2 : index, iree.fixedpoint.modified} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {iree.fixedpoint.iteration = 3 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {iree.fixedpoint.iteration = 3 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPOPass (iree-util-ipo) //----- //
module attributes {iree.fixedpoint.iteration = 3 : index} {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIteratorPass (iree-util-fixed-point-iterator) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %0 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
  %4 = util.cmp.eq %3, %0 : !hal.device
  %5 = arith.cmpi slt, %1, %device_count : index
  %6 = arith.andi %4, %5 : i1
  cf.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %1 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
  %8 = arith.cmpi eq, %2, %c0 : index
  %9 = arith.select %7, %c1, %c0 : index
  %10 = arith.addi %2, %9 : index
  %11 = arith.andi %7, %8 : i1
  %12 = arith.select %11, %device_n, %0 : !hal.device
  %13 = arith.addi %1, %c1 : index
  cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %4, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %3, @__device_0 : !hal.device
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c-1_i64 = arith.constant -1 : i64
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %c14_i32 = arith.constant 14 : i32
  %0 = util.null : !hal.executable
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0 = util.global.load @__device_0 : !hal.device
  %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  cf.cond_br %2, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb3(%executable : !hal.executable)
^bb2:  // pred: ^bb0
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInitializationOrderPass (iree-util-verify-initialization-order) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    util.return
  }
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.initializer {
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok, %value = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    util.return
  }
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.initializer {
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %0 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0 = util.global.load @__device_0 : !hal.device
    %1 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %2 = arith.cmpi eq, %1, %c0 : index
    cf.cond_br %2, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %executable = hal.executable.create device(%__device_0 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb3(%executable : !hal.executable)
  ^bb2:  // pred: ^bb0
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %0, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializersPass (iree-util-combine-initializers) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %0 : index, index, !hal.device)
  ^bb1(%1: index, %2: index, %3: !hal.device):  // 2 preds: ^bb0, ^bb4
    %4 = util.cmp.eq %3, %0 : !hal.device
    %5 = arith.cmpi slt, %1, %device_count : index
    %6 = arith.andi %4, %5 : i1
    cf.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %1 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%7: i1):  // 2 preds: ^bb2, ^bb3
    %8 = arith.cmpi eq, %2, %c0 : index
    %9 = arith.select %7, %c1, %c0 : index
    %10 = arith.addi %2, %9 : index
    %11 = arith.andi %7, %8 : i1
    %12 = arith.select %11, %device_n, %0 : !hal.device
    %13 = arith.addi %1, %c1 : index
    cf.br ^bb1(%13, %10, %12 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %4, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %3, @__device_0 : !hal.device
    cf.br ^bb8
  ^bb8:  // pred: ^bb7
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %c-1_i64 = arith.constant -1 : i64
    %c-1 = arith.constant -1 : index
    %c0_4 = arith.constant 0 : index
    %c14_i32 = arith.constant 14 : i32
    %14 = util.null : !hal.executable
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_5 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0_4, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0_4 : index
    cf.cond_br %16, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %executable = hal.executable.create device(%__device_0_5 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb11(%executable : !hal.executable)
  ^bb10:  // pred: ^bb8
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb11(%14 : !hal.executable)
  ^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    cf.br ^bb12
  ^bb12:  // pred: ^bb11
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After IREECodegenAffineExpandIndexOpsPass (iree-codegen-affine-expand-index-ops) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After IREECodegenLowerAffinePass (iree-codegen-lower-affine) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  cf.br ^bb8
^bb8:  // pred: ^bb7
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb9, ^bb10
^bb9:  // pred: ^bb8
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb11(%executable : !hal.executable)
^bb10:  // pred: ^bb8
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb11(%0 : !hal.executable)
^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  cf.br ^bb12
^bb12:  // pred: ^bb11
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ArithUnsignedWhenEquivalentPass (arith-unsigned-when-equivalent) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %4, @__device_0 : !hal.device
    cf.br ^bb8
  ^bb8:  // pred: ^bb7
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_4 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    cf.cond_br %16, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb11(%executable : !hal.executable)
  ^bb10:  // pred: ^bb8
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb11(%0 : !hal.executable)
  ^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    cf.br ^bb12
  ^bb12:  // pred: ^bb11
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After PropagateSubrangesPass (iree-util-propagate-subranges) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %4, @__device_0 : !hal.device
    cf.br ^bb8
  ^bb8:  // pred: ^bb7
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_4 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    cf.cond_br %16, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb11(%executable : !hal.executable)
  ^bb10:  // pred: ^bb8
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb11(%0 : !hal.executable)
  ^bb11(%17: !hal.executable):  // 2 preds: ^bb9, ^bb10
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    cf.br ^bb12
  ^bb12:  // pred: ^bb11
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After CSE (cse) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  util.global.store %4, @__device_0 : !hal.device
  %__device_0 = util.global.load @__device_0 : !hal.device
  %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  %__device_0_4 = util.global.load @__device_0 : !hal.device
  %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    util.global.store %4, @__device_0 : !hal.device
    %__device_0 = util.global.load @__device_0 : !hal.device
    %ok_2, %value_3 = hal.device.query<%__device_0 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_query_0_hal_executable_format_rocm_hsaco_fb = util.global.load @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
    %__device_0_4 = util.global.load @__device_0 : !hal.device
    %15 = arith.select %__device_0_query_0_hal_executable_format_rocm_hsaco_fb, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%__device_0_4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c-1_i64 = arith.constant -1 : i64
    %c8 = arith.constant 8 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c64 = arith.constant 64 : index
    %c8 = arith.constant 8 : index
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %c-1_i64 = arith.constant -1 : i64
  %c8 = arith.constant 8 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c64 = arith.constant 64 : index
  %c8 = arith.constant 8 : index
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccessesPass (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  %15 = arith.select %value_3, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  util.global.store %4, @__device_0 : !hal.device
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
  %c32 = arith.constant 32 : index
  %c2048 = arith.constant 2048 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c8 = arith.constant 8 : index
  %c-1_i64 = arith.constant -1 : i64
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
    (%c0 : index)[%c0, %c2048], 
    (%c1 : index)[%c0, %c32]
  ]) flags("None")
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  util.return %cmd : !hal.command_buffer
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
  %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
  %c8 = arith.constant 8 : index
  %c64 = arith.constant 64 : index
  %c2048 = arith.constant 2048 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %0 = util.null : !hal.fence
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %__device_0 = util.global.load immutable @__device_0 : !hal.device
  %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
  %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
    (%buffer : !hal.buffer)[%c0, %c2048], 
    (%transient_buffer : !hal.buffer)[%c0, %c32]
  ]) flags("None")
  %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
  util.return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatternsPass (iree-util-apply-patterns) //----- //
util.initializer {
  %0 = util.null : !hal.executable
  %c14_i32 = arith.constant 14 : i32
  %c-1 = arith.constant -1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c18_i32 = arith.constant 18 : i32
  %false = arith.constant false
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %1 = util.null : !hal.device
  %device_count = hal.devices.count : index
  cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
  %5 = util.cmp.eq %4, %1 : !hal.device
  %6 = arith.cmpi slt, %2, %device_count : index
  %7 = arith.andi %5, %6 : i1
  cf.cond_br %7, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %device_n = hal.devices.get %2 : !hal.device
  %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
  cf.cond_br %value, ^bb3, ^bb4(%false : i1)
^bb3:  // pred: ^bb2
  %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  cf.br ^bb4(%value_1 : i1)
^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
  %9 = arith.cmpi eq, %3, %c0 : index
  %10 = arith.select %8, %c1, %c0 : index
  %11 = arith.addi %3, %10 : index
  %12 = arith.andi %8, %9 : i1
  %13 = arith.select %12, %device_n, %1 : !hal.device
  %14 = arith.addi %2, %c1 : index
  cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
^bb5:  // pred: ^bb1
  cf.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  cf.br ^bb7
^bb7:  // 2 preds: ^bb5, ^bb6
  %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
  %15 = arith.select %value_3, %c0, %c-1 : index
  %16 = arith.cmpi eq, %15, %c0 : index
  util.global.store %4, @__device_0 : !hal.device
  util.global.store %value_3, @__device_0_query_0_hal_executable_format_rocm_hsaco_fb : i1
  cf.cond_br %16, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %executable = hal.executable.create device(%4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
  cf.br ^bb10(%executable : !hal.executable)
^bb9:  // pred: ^bb7
  util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  cf.br ^bb10(%0 : !hal.executable)
^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
  util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
  util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.return
}

// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    %15 = arith.select %value_3, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    util.global.store %4, @__device_0 : !hal.device
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module {
  util.global private @__device_0 : !hal.device
  util.global private @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
  util.global private @__reduce_memoize_result_0_device_0 : !hal.command_buffer
  util.initializer {
    %0 = util.null : !hal.executable
    %c14_i32 = arith.constant 14 : i32
    %c-1 = arith.constant -1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c18_i32 = arith.constant 18 : i32
    %false = arith.constant false
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %1 = util.null : !hal.device
    %device_count = hal.devices.count : index
    cf.br ^bb1(%c0, %c0, %1 : index, index, !hal.device)
  ^bb1(%2: index, %3: index, %4: !hal.device):  // 2 preds: ^bb0, ^bb4
    %5 = util.cmp.eq %4, %1 : !hal.device
    %6 = arith.cmpi slt, %2, %device_count : index
    %7 = arith.andi %5, %6 : i1
    cf.cond_br %7, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %device_n = hal.devices.get %2 : !hal.device
    %ok, %value = hal.device.query<%device_n : !hal.device> key("hal.device.id" :: "hip") : i1, i1 = false
    cf.cond_br %value, ^bb3, ^bb4(%false : i1)
  ^bb3:  // pred: ^bb2
    %ok_0, %value_1 = hal.device.query<%device_n : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    cf.br ^bb4(%value_1 : i1)
  ^bb4(%8: i1):  // 2 preds: ^bb2, ^bb3
    %9 = arith.cmpi eq, %3, %c0 : index
    %10 = arith.select %8, %c1, %c0 : index
    %11 = arith.addi %3, %10 : index
    %12 = arith.andi %8, %9 : i1
    %13 = arith.select %12, %device_n, %1 : !hal.device
    %14 = arith.addi %2, %c1 : index
    cf.br ^bb1(%14, %11, %13 : index, index, !hal.device)
  ^bb5:  // pred: ^bb1
    cf.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    util.status.check_ok %c18_i32, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %ok_2, %value_3 = hal.device.query<%4 : !hal.device> key("hal.executable.format" :: "rocm-hsaco-fb") : i1, i1 = false
    %15 = arith.select %value_3, %c0, %c-1 : index
    %16 = arith.cmpi eq, %15, %c0 : index
    util.global.store %4, @__device_0 : !hal.device
    cf.cond_br %16, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %executable = hal.executable.create device(%4 : !hal.device) affinity(%c-1_i64) target(@reduce_dispatch_0::@rocm_hsaco_fb) : !hal.executable
    cf.br ^bb10(%executable : !hal.executable)
  ^bb9:  // pred: ^bb7
    util.status.check_ok %c14_i32, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    cf.br ^bb10(%0 : !hal.executable)
  ^bb10(%17: !hal.executable):  // 2 preds: ^bb8, ^bb9
    util.global.store %17, @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %18 = util.call @__reduce_memoize_apply() : () -> !hal.command_buffer
    util.global.store %18, @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    util.return
  }
  hal.executable private @reduce_dispatch_0 {
    hal.executable.binary public @rocm_hsaco_fb attributes {data = dense<"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vector<5408xi8>, format = "rocm-hsaco-fb", mime_type = "application/x-flatbuffers"}
  }
  util.func private @__reduce_memoize_apply() -> !hal.command_buffer attributes {inlining_policy = #util.inline.never} {
    %c32 = arith.constant 32 : index
    %c2048 = arith.constant 2048 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c8 = arith.constant 8 : index
    %c-1_i64 = arith.constant -1 : i64
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__device_0_executable_0_reduce_dispatch_0 = util.global.load immutable @__device_0_executable_0_reduce_dispatch_0 : !hal.executable
    %cmd = hal.command_buffer.create device(%__device_0 : !hal.device) mode("None") categories("Transfer|Dispatch") affinity(%c-1_i64) bindings(%c2) : !hal.command_buffer
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%__device_0_executable_0_reduce_dispatch_0 : !hal.executable)[%c0] workgroups([%c8, %c1, %c1]) bindings([
      (%c0 : index)[%c0, %c2048], 
      (%c1 : index)[%c0, %c32]
    ]) flags("None")
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    util.return %cmd : !hal.command_buffer
  }
  util.func public @reduce(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %buffer_usage = hal.buffer_usage<"TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage"> : i32
    %memory_type = hal.memory_type<"DeviceVisible|DeviceLocal"> : i32
    %c8 = arith.constant 8 : index
    %c64 = arith.constant 64 : index
    %c2048 = arith.constant 2048 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %__device_0 = util.global.load immutable @__device_0 : !hal.device
    %__reduce_memoize_result_0_device_0 = util.global.load immutable @__reduce_memoize_result_0_device_0 : !hal.command_buffer
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c8, %c64]) type(%element_type_f32) encoding(%dense_row_major)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %allocator = hal.device.allocator<%__device_0 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2048) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type(%memory_type) usage(%buffer_usage) flags("None") : !hal.buffer{%c32}
    %fence_0 = hal.fence.create device(%__device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute.indirect<%__device_0 : !hal.device> affinity(%c-1_i64) wait(%fence) signal(%fence_0) commands(%__reduce_memoize_result_0_device_0) bindings([
      (%buffer : !hal.buffer)[%c0, %c2048], 
      (%transient_buffer : !hal.buffer)[%c0, %c32]
    ]) flags("None")
    %status = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) flags("None") : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c32] shape([%c8]) type(%element_type_f32) encoding(%dense_row_major) : !hal.buffer_view
    util.return %view : !hal.buffer_view
  }
}


// -----// IR Dump After ConversionPass (iree-vm-conversion) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c-1_0 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_1 = vm.const.i64.zero
      %c1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %5 = vm.and.i32 %req, %slt : i32
      vm.cond_br %5, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %6 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_device_id_C6650FF277232B5A" {alignment = 1 : i64} : !vm.buffer = "hal.device.id"
      %buffer_3 = vm.rodata.inline "_utf8_hip_2D25314D056B7F99" {alignment = 1 : i64} : !vm.buffer = "hip"
      %7:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_3) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %7#1 : i64
      %zero_4 = vm.const.i32.zero
      %8 = vm.select.i32 %7#0, %nz, %zero_4 : i32
      %c1_5 = vm.const.i32 1
      vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %buffer_6 = vm.rodata.inline "_utf8_hal_executable_format_E03EECB63A2AAF52" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_7 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
      %9:2 = vm.call @hal.device.query.i64(%ref, %buffer_6, %buffer_7) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_8 = vm.cmp.nz.i64 %9#1 : i64
      %zero_9 = vm.const.i32.zero
      %10 = vm.select.i32 %9#0, %nz_8, %zero_9 : i32
      %c1_10 = vm.const.i32 1
      vm.br ^bb4(%10 : i32)
    ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
      %12 = vm.select.i64 %11, %c1, %zero_1 : i64
      %13 = vm.add.i64 %3, %12 : i64
      %14 = vm.and.i32 %11, %eq : i32
      %ref_11 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
      %15 = vm.add.i64 %2, %c1 : i64
      vm.br ^bb1(%15, %13, %ref_11 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %req, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
      vm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      %buffer_12 = vm.rodata.inline "_utf8_hal_executable_format_E03EECB63A2AAF52" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_13 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
      %16:2 = vm.call @hal.device.query.i64(%4, %buffer_12, %buffer_13) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_14 = vm.cmp.nz.i64 %16#1 : i64
      %zero_15 = vm.const.i32.zero
      %17 = vm.select.i32 %16#0, %nz_14, %zero_15 : i32
      %c1_16 = vm.const.i32 1
      %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
      %eq_17 = vm.cmp.eq.i64 %18, %zero_1 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_17, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %buffer_18 = vm.rodata.inline "reduce_dispatch_0_rocm_hsaco_fb" {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} : !vm.buffer = dense<"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vector<5408xi8>
      %buffer_19 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
      %null_20 = vm.const.ref.zero : !vm.buffer
      %ref_21 = vm.call @hal.executable.create(%4, %c-1_0, %buffer_19, %buffer_18, %null_20) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.br ^bb10(%ref_21 : !vm.ref<!hal.executable>)
    ^bb9:  // pred: ^bb7
      vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      vm.br ^bb10(%null : !vm.ref<!hal.executable>)
    ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
      vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_22 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_22, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %c1 = vm.const.i64 1
      %zero = vm.const.i64.zero
      %c2 = vm.const.i64 2
      %c8 = vm.const.i64 8
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %zero_0 = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c2_1 = vm.const.i32 2
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero_0, %c3, %c-1, %c2_1) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      %zero_2 = vm.const.i32.zero
      %zero_3 = vm.const.i32.zero
      %c8_4 = vm.const.i32 8
      %c1_5 = vm.const.i32 1
      %c1_6 = vm.const.i32 1
      %zero_7 = vm.const.i64 0
      %zero_8 = vm.const.i32.zero
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1_9 = vm.const.i32 1
      %null_10 = vm.const.ref.zero : !vm.ref<!hal.buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero_3, %c8_4, %c1_5, %c1_6, %zero_7, [], [(%zero_2, %zero_8, %null, %zero, %c2048), (%zero_2, %c1_9, %null_10, %zero, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_11 = vm.const.i64.zero
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_11) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.select(%memory_types : i32, %buffer_usage : i32, %flags : i64, %from : tuple<!vm.ref<!hal.device>, i64> ...) -> (!vm.ref<!hal.device>, i64) attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.allocation.preserve(%buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.buffer.allocation.discard(%buffer : !vm.ref<!hal.buffer>) -> i32
    vm.import private @hal.buffer.allocation.is_terminal(%buffer : !vm.ref<!hal.buffer>) -> i32
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i64, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i64) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.advise_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %buffer : !vm.ref<!hal.buffer>, %flags : i64, %arg0 : i64, %arg1 : i64, %buffer_slot : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i64, %pattern_length : i32, %flags : i64)
    vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %flags : i64)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>, %flags : i64)
    vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
    vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i64)
    vm.import private @hal.device.queue.barrier(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %flags : i64)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64)
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%flags : i64, %fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %buffer = vm.rodata.inline "_utf8_input0_DCE99660CEB3F6B" {alignment = 1 : i64} : !vm.buffer = "input0"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_3 = vm.rodata.inline "_utf8_tensor_FC1814BC4A58F22A" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16 = vm.const.i32 16
      %c3075_4 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_3, %ref_2, %c2048, %c16, %c3075_4) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %zero_5 = vm.const.i64.zero
      %ref_6 = vm.call @hal.fence.create(%__device_0, %zero_5) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %zero_7 = vm.const.i64.zero
      %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_6, %zero_0, %c48, %c3075, %c32, %zero_7) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %zero_9 = vm.const.i64.zero
      %ref_10 = vm.call @hal.fence.create(%__device_0, %zero_9) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %zero_11 = vm.const.i64 0
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_6, %ref_10, %__reduce_memoize_result_0_device_0, %zero_11, [(%ref, %zero, %c2048), (%ref_8, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %zero_12 = vm.const.i64.zero
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, %zero_12, [%ref_10]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %0, "failed to wait on timepoint"
      %ref_13 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_13 : !vm.ref<!hal.buffer_view>
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After ReifyRodataTablesPass (iree-vm-reify-rodata-tables) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c-1_0 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %buffer = vm.rodata.inline "_utf8_hal_device_id_C6650FF277232B5A" {alignment = 1 : i64} : !vm.buffer = "hal.device.id"
    %buffer_3 = vm.rodata.inline "_utf8_hip_2D25314D056B7F99" {alignment = 1 : i64} : !vm.buffer = "hip"
    %7:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_3) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_4 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_4 : i32
    %c1_5 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %buffer_6 = vm.rodata.inline "_utf8_hal_executable_format_E03EECB63A2AAF52" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
    %buffer_7 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
    %9:2 = vm.call @hal.device.query.i64(%ref, %buffer_6, %buffer_7) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_8 = vm.cmp.nz.i64 %9#1 : i64
    %zero_9 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_8, %zero_9 : i32
    %c1_10 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
    %12 = vm.select.i64 %11, %c1, %zero_1 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_11 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_11 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %buffer_12 = vm.rodata.inline "_utf8_hal_executable_format_E03EECB63A2AAF52" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
    %buffer_13 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
    %16:2 = vm.call @hal.device.query.i64(%4, %buffer_12, %buffer_13) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_14 = vm.cmp.nz.i64 %16#1 : i64
    %zero_15 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_14, %zero_15 : i32
    %c1_16 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
    %eq_17 = vm.cmp.eq.i64 %18, %zero_1 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_17, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %buffer_18 = vm.rodata.inline "reduce_dispatch_0_rocm_hsaco_fb" {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} : !vm.buffer = dense<"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vector<5408xi8>
    %buffer_19 = vm.rodata.inline "_utf8_rocm_hsaco_fb_1C72FE9185115983" {alignment = 1 : i64} : !vm.buffer = "rocm-hsaco-fb"
    %null_20 = vm.const.ref.zero : !vm.buffer
    %ref_21 = vm.call @hal.executable.create(%4, %c-1_0, %buffer_19, %buffer_18, %null_20) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_21 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_22 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_22, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %c2 = vm.const.i64 2
    %c8 = vm.const.i64 8
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %zero_0 = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c2_1 = vm.const.i32 2
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero_0, %c3, %c-1, %c2_1) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %zero_2 = vm.const.i32.zero
    %zero_3 = vm.const.i32.zero
    %c8_4 = vm.const.i32 8
    %c1_5 = vm.const.i32 1
    %c1_6 = vm.const.i32 1
    %zero_7 = vm.const.i64 0
    %zero_8 = vm.const.i32.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1_9 = vm.const.i32 1
    %null_10 = vm.const.ref.zero : !vm.ref<!hal.buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero_3, %c8_4, %c1_5, %c1_6, %zero_7, [], [(%zero_2, %zero_8, %null, %zero, %c2048), (%zero_2, %c1_9, %null_10, %zero, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_11 = vm.const.i64.zero
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_11) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.select(%memory_types : i32, %buffer_usage : i32, %flags : i64, %from : tuple<!vm.ref<!hal.device>, i64> ...) -> (!vm.ref<!hal.device>, i64) attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.allocation.preserve(%buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.buffer.allocation.discard(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.allocation.is_terminal(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i64, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i64) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.advise_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %buffer : !vm.ref<!hal.buffer>, %flags : i64, %arg0 : i64, %arg1 : i64, %buffer_slot : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %flags : i64)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>, %flags : i64)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.barrier(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %flags : i64)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%flags : i64, %fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %buffer = vm.rodata.inline "_utf8_input0_DCE99660CEB3F6B" {alignment = 1 : i64} : !vm.buffer = "input0"
    vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %buffer_3 = vm.rodata.inline "_utf8_tensor_FC1814BC4A58F22A" {alignment = 1 : i64} : !vm.buffer = "tensor"
    %c16 = vm.const.i32 16
    %c3075_4 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %buffer_3, %ref_2, %c2048, %c16, %c3075_4) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_5 = vm.const.i64.zero
    %ref_6 = vm.call @hal.fence.create(%__device_0, %zero_5) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_7 = vm.const.i64.zero
    %ref_8 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_6, %zero_0, %c48, %c3075, %c32, %zero_7) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %zero_9 = vm.const.i64.zero
    %ref_10 = vm.call @hal.fence.create(%__device_0, %zero_9) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_11 = vm.const.i64 0
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_6, %ref_10, %__reduce_memoize_result_0_device_0, %zero_11, [(%ref, %zero, %c2048), (%ref_8, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_12 = vm.const.i64.zero
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, %zero_12, [%ref_10]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_13 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_13 : !vm.ref<!hal.buffer_view>
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52_0 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983_1 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983_2 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c-1_0 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_3 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_3 : i32
    %c1_4 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_5 = vm.cmp.nz.i64 %9#1 : i64
    %zero_6 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_5, %zero_6 : i32
    %c1_7 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
    %12 = vm.select.i64 %11, %c1, %zero_1 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_8 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_8 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_E03EECB63A2AAF52_0 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52_0 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_1 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983_1 : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_0, %_utf8_rocm_hsaco_fb_1C72FE9185115983_1) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_9 = vm.cmp.nz.i64 %16#1 : i64
    %zero_10 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_9, %zero_10 : i32
    %c1_11 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
    %eq_12 = vm.cmp.eq.i64 %18, %zero_1 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_12, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_2 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983_2 : !vm.buffer
    %null_13 = vm.const.ref.zero : !vm.buffer
    %ref_14 = vm.call @hal.executable.create(%4, %c-1_0, %_utf8_rocm_hsaco_fb_1C72FE9185115983_2, %reduce_dispatch_0_rocm_hsaco_fb, %null_13) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_14 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_15 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_15, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %c2 = vm.const.i64 2
    %c8 = vm.const.i64 8
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %zero_0 = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c2_1 = vm.const.i32 2
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero_0, %c3, %c-1, %c2_1) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %zero_2 = vm.const.i32.zero
    %zero_3 = vm.const.i32.zero
    %c8_4 = vm.const.i32 8
    %c1_5 = vm.const.i32 1
    %c1_6 = vm.const.i32 1
    %zero_7 = vm.const.i64 0
    %zero_8 = vm.const.i32.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1_9 = vm.const.i32 1
    %null_10 = vm.const.ref.zero : !vm.ref<!hal.buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero_3, %c8_4, %c1_5, %c1_6, %zero_7, [], [(%zero_2, %zero_8, %null, %zero, %c2048), (%zero_2, %c1_9, %null_10, %zero, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_11 = vm.const.i64.zero
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_11) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.select(%memory_types : i32, %buffer_usage : i32, %flags : i64, %from : tuple<!vm.ref<!hal.device>, i64> ...) -> (!vm.ref<!hal.device>, i64) attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.allocation.preserve(%buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.buffer.allocation.discard(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.allocation.is_terminal(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i64, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i64) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.advise_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %buffer : !vm.ref<!hal.buffer>, %flags : i64, %arg0 : i64, %arg1 : i64, %buffer_slot : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %flags : i64)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>, %flags : i64)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.barrier(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %flags : i64)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%flags : i64, %fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075_3 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_2, %c2048, %c16, %c3075_3) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_4 = vm.const.i64.zero
    %ref_5 = vm.call @hal.fence.create(%__device_0, %zero_4) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_6 = vm.const.i64.zero
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_5, %zero_0, %c48, %c3075, %c32, %zero_6) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %zero_8 = vm.const.i64.zero
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero_8) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_10 = vm.const.i64 0
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_5, %ref_9, %__reduce_memoize_result_0_device_0, %zero_10, [(%ref, %zero, %c2048), (%ref_7, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_11 = vm.const.i64.zero
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, %zero_11, [%ref_9]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_12 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_12 : !vm.ref<!hal.buffer_view>
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c-1_0 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %zero_3 = vm.const.i32.zero
    %8 = vm.select.i32 %7#0, %nz, %zero_3 : i32
    %c1_4 = vm.const.i32 1
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_5 = vm.cmp.nz.i64 %9#1 : i64
    %zero_6 = vm.const.i32.zero
    %10 = vm.select.i32 %9#0, %nz_5, %zero_6 : i32
    %c1_7 = vm.const.i32 1
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
    %12 = vm.select.i64 %11, %c1, %zero_1 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_8 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_8 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_E03EECB63A2AAF52_9 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_10 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_9, %_utf8_rocm_hsaco_fb_1C72FE9185115983_10) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_11 = vm.cmp.nz.i64 %16#1 : i64
    %zero_12 = vm.const.i32.zero
    %17 = vm.select.i32 %16#0, %nz_11, %zero_12 : i32
    %c1_13 = vm.const.i32 1
    %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
    %eq_14 = vm.cmp.eq.i64 %18, %zero_1 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_14, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_15 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %null_16 = vm.const.ref.zero : !vm.buffer
    %ref_17 = vm.call @hal.executable.create(%4, %c-1_0, %_utf8_rocm_hsaco_fb_1C72FE9185115983_15, %reduce_dispatch_0_rocm_hsaco_fb, %null_16) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_17 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    vm.br ^bb10(%null : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_18 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_18, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %c1 = vm.const.i64 1
    %zero = vm.const.i64.zero
    %c2 = vm.const.i64 2
    %c8 = vm.const.i64 8
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %zero_0 = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c2_1 = vm.const.i32 2
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero_0, %c3, %c-1, %c2_1) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    %zero_2 = vm.const.i32.zero
    %zero_3 = vm.const.i32.zero
    %c8_4 = vm.const.i32 8
    %c1_5 = vm.const.i32 1
    %c1_6 = vm.const.i32 1
    %zero_7 = vm.const.i64 0
    %zero_8 = vm.const.i32.zero
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1_9 = vm.const.i32 1
    %null_10 = vm.const.ref.zero : !vm.ref<!hal.buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero_3, %c8_4, %c1_5, %c1_6, %zero_7, [], [(%zero_2, %zero_8, %null, %zero, %c2048), (%zero_2, %c1_9, %null_10, %zero, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_11 = vm.const.i64.zero
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_11) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.select(%memory_types : i32, %buffer_usage : i32, %flags : i64, %from : tuple<!vm.ref<!hal.device>, i64> ...) -> (!vm.ref<!hal.device>, i64) attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.allocation.preserve(%buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.buffer.allocation.discard(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.allocation.is_terminal(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i64, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i64) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.advise_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %buffer : !vm.ref<!hal.buffer>, %flags : i64, %arg0 : i64, %arg1 : i64, %buffer_slot : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %flags : i64)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>, %flags : i64)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.barrier(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %flags : i64)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%flags : i64, %fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075_3 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_2, %c2048, %c16, %c3075_3) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_4 = vm.const.i64.zero
    %ref_5 = vm.call @hal.fence.create(%__device_0, %zero_4) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_6 = vm.const.i64.zero
    %ref_7 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_5, %zero_0, %c48, %c3075, %c32, %zero_6) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %zero_8 = vm.const.i64.zero
    %ref_9 = vm.call @hal.fence.create(%__device_0, %zero_8) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %zero_10 = vm.const.i64 0
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_5, %ref_9, %__reduce_memoize_result_0_device_0, %zero_10, [(%ref, %zero, %c2048), (%ref_7, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_11 = vm.const.i64.zero
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, %zero_11, [%ref_9]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_12 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_12 : !vm.ref<!hal.buffer_view>
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.initializer {
    %null = vm.const.ref.zero : !vm.buffer
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %5 = vm.and.i32 %req, %slt : i32
    vm.cond_br %5, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %6 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %7#1 : i64
    %8 = vm.select.i32 %7#0, %nz, %zero : i32
    vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %9#1 : i64
    %10 = vm.select.i32 %9#0, %nz_3, %zero : i32
    vm.br ^bb4(%10 : i32)
  ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
    %12 = vm.select.i64 %11, %c1, %zero_1 : i64
    %13 = vm.add.i64 %3, %12 : i64
    %14 = vm.and.i32 %11, %eq : i32
    %ref_4 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
    %15 = vm.add.i64 %2, %c1 : i64
    vm.br ^bb1(%15, %13, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %req, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
    vm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %16#1 : i64
    %17 = vm.select.i32 %16#0, %nz_7, %zero : i32
    %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %18, %zero_1 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.br ^bb10(%ref_10 : !vm.ref<!hal.executable>)
  ^bb9:  // pred: ^bb7
    vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    vm.br ^bb10(%null_0 : !vm.ref<!hal.executable>)
  ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
    vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.select(%memory_types : i32, %buffer_usage : i32, %flags : i64, %from : tuple<!vm.ref<!hal.device>, i64> ...) -> (!vm.ref<!hal.device>, i64) attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.allocation.preserve(%buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.buffer.allocation.discard(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.allocation.is_terminal(%buffer : !vm.ref<!hal.buffer>) -> i32
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i64, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i64) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.advise_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %buffer : !vm.ref<!hal.buffer>, %flags : i64, %arg0 : i64, %arg1 : i64, %buffer_slot : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.command_buffer.update_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %target_buffer_slot : i32, %flags : i64)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer_slot : i32, %target_buffer_slot : i32, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer_slot : i32, %recv_buffer_slot : i32, %send_buffer : !vm.ref<!hal.buffer>, %recv_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer_slot : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>, %flags : i64)
  vm.import private @hal.device.queue.fill(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i64, %pattern_length : i32, %flags : i64)
  vm.import private @hal.device.queue.update(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.buffer, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.copy(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i64)
  vm.import private @hal.device.queue.barrier(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %flags : i64)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64)
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%flags : i64, %fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x4849503100000000E0140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C000000484950310000000046EBFFFF08000000C4000000010000000400000052EBFFFF300000004000000001000000010000000800000048000000020000000300000000000000020000000000000000000000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000BAEBFFFF2800000004000000C6EBFFFF08000000040000000E000000726564756374696F6E2E6D6C69720000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000010000000400000020ECFFFF04000000D01300007F454C460201014003000000000000000300E000010000000000000000000000400000000000000010100000000000004C05000040003800080040000F000D000600000004000000400000000000000040000000000000004000000000000000C001000000000000C0010000000000000800000000000000010000000400000000000000000000000000000000000000000000000000000000060000000000000006000000000000001000000000000001000000050000000006000000000000001600000000000000160000000000000006000000000000000600000000000000100000000000000100000006000000000C000000000000002C000000000000002C0000000000007000000000000000000400000000000000100000000000000200000006000000000C000000000000002C000000000000002C00000000000070000000000000007000000000000000080000000000000052E5746404000000000C000000000000002C000000000000002C00000000000070000000000000000004000000000000010000000000000051E57464060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000004000000000200000000000000020000000000000002000000000000A402000000000000A4020000000000000400000000000000070000008E02000020000000414D44475055000083AE616D646873612E6B65726E656C7391DE0011AB2E616770725F636F756E7400A52E617267739285AE2E61637475616C5F616363657373A9726561645F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657400A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F62756666657285AE2E61637475616C5F616363657373AA77726974655F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657408A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F627566666572B92E67726F75705F7365676D656E745F66697865645F73697A6500B62E6B65726E6172675F7365676D656E745F616C69676E08B52E6B65726E6172675F7365676D656E745F73697A6510B82E6D61785F666C61745F776F726B67726F75705F73697A6540A52E6E616D65D9247265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332BB2E707269766174655F7365676D656E745F66697865645F73697A6500B42E726571645F776F726B67726F75705F73697A6593400101AB2E736770725F636F756E7412B12E736770725F7370696C6C5F636F756E7400A72E73796D626F6CD9277265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64B82E756E69666F726D5F776F726B5F67726F75705F73697A6501B32E757365735F64796E616D69635F737461636BC2AB2E766770725F636F756E7403B12E766770725F7370696C6C5F636F756E7400AF2E7761766566726F6E745F73697A6540AD616D646873612E746172676574B9616D6467636E2D616D642D616D646873612D2D676678393432AE616D646873612E76657273696F6E92010200000000000000000000000000000000000000000000000000000000000001000000120307000016000000000000C8010000000000002600000011000600C00500000000000040000000000000000100000001000000010000001A000000800004000404000001000000EAD60688873820480300000003000000010000000000000002000000000000000000000000000000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B640000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000040100000000000000000000000000000000000000000000000000000000000008000AF008C0000000800040000000000800006C000000000000106C0080000007FC08CBF3A0082BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF060080BE020188BE8200022409FF0986FFFF0000FF008BBE0070020000080AB0010000D200100504001050E0010102808000947D700F8CBF80020202010080BFFA02020201B108FF010080BFFA020202014E08FF010080BFFA020202014109FF010080BFFA020202014009FF0103047E010080BFFA02047E024201AF02030202010080BFFA020202014309FF000080BF010089D2017F01006A2082BE090088BF0082008E05FF0586FFFF0000A00086BE0B0087BE0102027E0002007E001070E000010180000081BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF0600000000000000A8040000000000000B000000000000001800000000000000050000000000000034050000000000000A000000000000004E00000000000000F5FEFF6F00000000F00400000000000004000000000000001405000000000000000000000000000000000000000000004952454500000000000000000000000000000000000000000000000000000000010000000000F1FF00000000000000000000000000000000370000000000F1FF03000000000000000000000000000000650000000000F1FF00000000000000000000000000000000930000000000F1FF0C000000000000000000000000000000C60000000000F1FF01000000000000000000000000000000F40000000000F1FF000000000000000000000000000000002B0100000000F1FF00000000000000000000000000000000640100000000F1FF00000000000000000000000000000000E401000000020800002C000000000000000000000000000097010000120307000016000000000000C801000000000000BC01000011000600C0050000000000004000000000000000002E6E6F7465002E64796E73796D002E676E752E68617368002E68617368002E64796E737472002E726F64617461002E74657874002E64796E616D6963002E72656C726F5F70616464696E67002E414D444750552E6770725F6D6178696D756D73002E636F6D6D656E74002E73796D746162002E7368737472746162002E73747274616200007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E707269766174655F7365675F73697A65007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F76677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F61677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D62657265645F73677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F766363007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F666C61745F73637261746368007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F64796E5F73697A65645F737461636B007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F726563757273696F6E007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64005F44594E414D494300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000007000000020000000000000000020000000000000002000000000000A402000000000000000000000000000004000000000000000000000000000000070000000B0000000200000000000000A804000000000000A80400000000000048000000000000000500000001000000080000000000000018000000000000000F000000F6FFFF6F0200000000000000F004000000000000F0040000000000002400000000000000020000000000000008000000000000000000000000000000190000000500000002000000000000001405000000000000140500000000000020000000000000000200000000000000040000000000000004000000000000001F000000030000000200000000000000340500000000000034050000000000004E0000000000000000000000000000000100000000000000000000000000000027000000010000000200000000000000C005000000000000C00500000000000040000000000000000000000000000000400000000000000000000000000000002F00000001000000060000000000000000160000000000000006000000000000000600000000000000000000000000000001000000000000000000000000000035000000060000000300000000000000002C000000000000000C00000000000070000000000000000500000000000000080000000000000010000000000000003E000000080000000300000000000000702C000000000000700C00000000000090030000000000000000000000000000010000000000000000000000000000004D0000000100000000000000000000000000000000000000700C0000000000000000000000000000000000000000000001000000000000000000000000000000620000000100000030000000000000000000000000000000700C00000000000005000000000000000000000000000000010000000000000001000000000000006B0000000200000000000000000000000000000000000000780C00000000000020010000000000000E0000000A00000008000000000000001800000000000000730000000300000000000000000000000000000000000000980D00000000000085000000000000000000000000000000010000000000000000000000000000007D00000003000000000000000000000000000000000000001D0E000000000000ED010000000000000000000000000000010000000000000000000000000000000000000006000800040008000C000400080012001C000000040008000000000014001800"> : vector<5408xi8>
    vm.initializer {
      %null = vm.const.ref.zero : !vm.buffer
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_1 = vm.const.i64.zero
      %c1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_1, %zero_1, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %req = vm.cmp.eq.ref %4, %null_2 : !vm.ref<!hal.device>
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %5 = vm.and.i32 %req, %slt : i32
      vm.cond_br %5, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %6 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%6) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %7:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %7#1 : i64
      %8 = vm.select.i32 %7#0, %nz, %zero : i32
      vm.cond_br %8, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %9:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %9#1 : i64
      %10 = vm.select.i32 %9#0, %nz_3, %zero : i32
      vm.br ^bb4(%10 : i32)
    ^bb4(%11: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_1 : i64
      %12 = vm.select.i64 %11, %c1, %zero_1 : i64
      %13 = vm.add.i64 %3, %12 : i64
      %14 = vm.and.i32 %11, %eq : i32
      %ref_4 = vm.select.ref %14, %ref, %null_2 : !vm.ref<!hal.device>
      %15 = vm.add.i64 %2, %c1 : i64
      vm.br ^bb1(%15, %13, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %req, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.cond_fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<"hip", [#hal.executable.target<"rocm", "rocm-hsaco-fb", {abi = "hip", iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<"iree_default_tuning_spec_gfx942.mlir">, iree_codegen.target_info = #iree_gpu.target<arch = "gfx942", features = "", wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = "none"}>]>"
      vm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %16:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %16#1 : i64
      %17 = vm.select.i32 %16#0, %nz_7, %zero : i32
      %18 = vm.select.i64 %17, %zero_1, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %18, %zero_1 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.br ^bb10(%ref_10 : !vm.ref<!hal.executable>)
    ^bb9:  // pred: ^bb7
      vm.cond_fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
      vm.br ^bb10(%null_0 : !vm.ref<!hal.executable>)
    ^bb10(%19: !vm.ref<!hal.executable>):  // 2 preds: ^bb8, ^bb9
      vm.global.store.ref %19, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %0, "failed to wait on timepoint"
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.initializer {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2(%0 : i32), ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2(%1: i32):  // pred: ^bb0
    vm.fail %1, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
  %c1 = vm.const.i32 1
  %c8 = vm.const.i32 8
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %zero = vm.const.i32.zero
  %c32 = vm.const.i64 32
  %c2048 = vm.const.i64 2048
  %zero_0 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
  %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
  vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
  vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
  vm.return %ref : !vm.ref<!hal.command_buffer>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %c1 = vm.const.i32 1
  %null = vm.const.ref.zero : !vm.buffer
  %c14 = vm.const.i32 14
  %c-1 = vm.const.i64 -1
  %c18 = vm.const.i32 18
  %zero = vm.const.i32.zero
  %zero_0 = vm.const.i64.zero
  %c1_1 = vm.const.i64 1
  %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
  %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
  %1 = vm.ext.i32.i64.s %0 : i32 -> i64
  vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
  %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
  %5 = vm.xor.i32 %rnz, %c1 : i32
  %slt = vm.cmp.lt.i64.s %2, %1 : i64
  %6 = vm.and.i32 %5, %slt : i32
  vm.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %7 = vm.trunc.i64.i32 %2 : i64 -> i32
  %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
  %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
  %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
  %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz = vm.cmp.nz.i64 %8#1 : i64
  %9 = vm.select.i32 %8#0, %nz, %zero : i32
  vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
^bb3:  // pred: ^bb2
  %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
  %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
  %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_3 = vm.cmp.nz.i64 %10#1 : i64
  %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
  vm.br ^bb4(%11 : i32)
^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
  %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
  %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
  %14 = vm.add.i64 %3, %13 : i64
  %15 = vm.and.i32 %12, %eq : i32
  %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
  %16 = vm.add.i64 %2, %c1_1 : i64
  vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
^bb5:  // pred: ^bb1
  vm.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
^bb7:  // pred: ^bb5
  %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
  %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
  %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_7 = vm.cmp.nz.i64 %17#1 : i64
  %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
  %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
  %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
  vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
  vm.cond_br %eq_8, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
  %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
  %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
  vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
  vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.return
^bb9:  // pred: ^bb7
  vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c16 = vm.const.i32 16
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %c3075 = vm.const.i32 3075
  %c48 = vm.const.i32 48
  %c8 = vm.const.i64 8
  %c64 = vm.const.i64 64
  %c2048 = vm.const.i64 2048
  %c32 = vm.const.i64 32
  %zero = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c-1_0 = vm.const.i32 -1
  %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
  %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
  %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %0, ^bb2(%0 : i32), ^bb1
^bb1:  // pred: ^bb0
  %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_5 : !vm.ref<!hal.buffer_view>
^bb2(%1: i32):  // pred: ^bb0
  vm.fail %1, "failed to wait on timepoint"
}

// -----// IR Dump After Inliner (inline) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x4849503100000000E0140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C000000484950310000000046EBFFFF08000000C4000000010000000400000052EBFFFF300000004000000001000000010000000800000048000000020000000300000000000000020000000000000000000000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000BAEBFFFF2800000004000000C6EBFFFF08000000040000000E000000726564756374696F6E2E6D6C69720000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000010000000400000020ECFFFF04000000D01300007F454C460201014003000000000000000300E000010000000000000000000000400000000000000010100000000000004C05000040003800080040000F000D000600000004000000400000000000000040000000000000004000000000000000C001000000000000C0010000000000000800000000000000010000000400000000000000000000000000000000000000000000000000000000060000000000000006000000000000001000000000000001000000050000000006000000000000001600000000000000160000000000000006000000000000000600000000000000100000000000000100000006000000000C000000000000002C000000000000002C0000000000007000000000000000000400000000000000100000000000000200000006000000000C000000000000002C000000000000002C00000000000070000000000000007000000000000000080000000000000052E5746404000000000C000000000000002C000000000000002C00000000000070000000000000000004000000000000010000000000000051E57464060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000004000000000200000000000000020000000000000002000000000000A402000000000000A4020000000000000400000000000000070000008E02000020000000414D44475055000083AE616D646873612E6B65726E656C7391DE0011AB2E616770725F636F756E7400A52E617267739285AE2E61637475616C5F616363657373A9726561645F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657400A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F62756666657285AE2E61637475616C5F616363657373AA77726974655F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657408A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F627566666572B92E67726F75705F7365676D656E745F66697865645F73697A6500B62E6B65726E6172675F7365676D656E745F616C69676E08B52E6B65726E6172675F7365676D656E745F73697A6510B82E6D61785F666C61745F776F726B67726F75705F73697A6540A52E6E616D65D9247265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332BB2E707269766174655F7365676D656E745F66697865645F73697A6500B42E726571645F776F726B67726F75705F73697A6593400101AB2E736770725F636F756E7412B12E736770725F7370696C6C5F636F756E7400A72E73796D626F6CD9277265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64B82E756E69666F726D5F776F726B5F67726F75705F73697A6501B32E757365735F64796E616D69635F737461636BC2AB2E766770725F636F756E7403B12E766770725F7370696C6C5F636F756E7400AF2E7761766566726F6E745F73697A6540AD616D646873612E746172676574B9616D6467636E2D616D642D616D646873612D2D676678393432AE616D646873612E76657273696F6E92010200000000000000000000000000000000000000000000000000000000000001000000120307000016000000000000C8010000000000002600000011000600C00500000000000040000000000000000100000001000000010000001A000000800004000404000001000000EAD60688873820480300000003000000010000000000000002000000000000000000000000000000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B640000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000040100000000000000000000000000000000000000000000000000000000000008000AF008C0000000800040000000000800006C000000000000106C0080000007FC08CBF3A0082BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF060080BE020188BE8200022409FF0986FFFF0000FF008BBE0070020000080AB0010000D200100504001050E0010102808000947D700F8CBF80020202010080BFFA02020201B108FF010080BFFA020202014E08FF010080BFFA020202014109FF010080BFFA020202014009FF0103047E010080BFFA02047E024201AF02030202010080BFFA020202014309FF000080BF010089D2017F01006A2082BE090088BF0082008E05FF0586FFFF0000A00086BE0B0087BE0102027E0002007E001070E000010180000081BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF0600000000000000A8040000000000000B000000000000001800000000000000050000000000000034050000000000000A000000000000004E00000000000000F5FEFF6F00000000F00400000000000004000000000000001405000000000000000000000000000000000000000000004952454500000000000000000000000000000000000000000000000000000000010000000000F1FF00000000000000000000000000000000370000000000F1FF03000000000000000000000000000000650000000000F1FF00000000000000000000000000000000930000000000F1FF0C000000000000000000000000000000C60000000000F1FF01000000000000000000000000000000F40000000000F1FF000000000000000000000000000000002B0100000000F1FF00000000000000000000000000000000640100000000F1FF00000000000000000000000000000000E401000000020800002C000000000000000000000000000097010000120307000016000000000000C801000000000000BC01000011000600C0050000000000004000000000000000002E6E6F7465002E64796E73796D002E676E752E68617368002E68617368002E64796E737472002E726F64617461002E74657874002E64796E616D6963002E72656C726F5F70616464696E67002E414D444750552E6770725F6D6178696D756D73002E636F6D6D656E74002E73796D746162002E7368737472746162002E73747274616200007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E707269766174655F7365675F73697A65007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F76677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F61677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D62657265645F73677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F766363007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F666C61745F73637261746368007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F64796E5F73697A65645F737461636B007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F726563757273696F6E007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64005F44594E414D494300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000007000000020000000000000000020000000000000002000000000000A402000000000000000000000000000004000000000000000000000000000000070000000B0000000200000000000000A804000000000000A80400000000000048000000000000000500000001000000080000000000000018000000000000000F000000F6FFFF6F0200000000000000F004000000000000F0040000000000002400000000000000020000000000000008000000000000000000000000000000190000000500000002000000000000001405000000000000140500000000000020000000000000000200000000000000040000000000000004000000000000001F000000030000000200000000000000340500000000000034050000000000004E0000000000000000000000000000000100000000000000000000000000000027000000010000000200000000000000C005000000000000C00500000000000040000000000000000000000000000000400000000000000000000000000000002F00000001000000060000000000000000160000000000000006000000000000000600000000000000000000000000000001000000000000000000000000000035000000060000000300000000000000002C000000000000000C00000000000070000000000000000500000000000000080000000000000010000000000000003E000000080000000300000000000000702C000000000000700C00000000000090030000000000000000000000000000010000000000000000000000000000004D0000000100000000000000000000000000000000000000700C0000000000000000000000000000000000000000000001000000000000000000000000000000620000000100000030000000000000000000000000000000700C00000000000005000000000000000000000000000000010000000000000001000000000000006B0000000200000000000000000000000000000000000000780C00000000000020010000000000000E0000000A00000008000000000000001800000000000000730000000300000000000000000000000000000000000000980D00000000000085000000000000000000000000000000010000000000000000000000000000007D00000003000000000000000000000000000000000000001D0E000000000000ED010000000000000000000000000000010000000000000000000000000000000000000006000800040008000C000400080012001C000000040008000000000014001800"> : vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2(%0 : i32), ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2(%1: i32):  // pred: ^bb0
      vm.fail %1, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After DropUnusedCallsPass (iree-vm-drop-unused-calls) //----- //
vm.module public @module {
  vm.global.ref private @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x4849503100000000E0140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C000000484950310000000046EBFFFF08000000C4000000010000000400000052EBFFFF300000004000000001000000010000000800000048000000020000000300000000000000020000000000000000000000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000BAEBFFFF2800000004000000C6EBFFFF08000000040000000E000000726564756374696F6E2E6D6C69720000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000010000000400000020ECFFFF04000000D01300007F454C460201014003000000000000000300E000010000000000000000000000400000000000000010100000000000004C05000040003800080040000F000D000600000004000000400000000000000040000000000000004000000000000000C001000000000000C0010000000000000800000000000000010000000400000000000000000000000000000000000000000000000000000000060000000000000006000000000000001000000000000001000000050000000006000000000000001600000000000000160000000000000006000000000000000600000000000000100000000000000100000006000000000C000000000000002C000000000000002C0000000000007000000000000000000400000000000000100000000000000200000006000000000C000000000000002C000000000000002C00000000000070000000000000007000000000000000080000000000000052E5746404000000000C000000000000002C000000000000002C00000000000070000000000000000004000000000000010000000000000051E57464060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000004000000000200000000000000020000000000000002000000000000A402000000000000A4020000000000000400000000000000070000008E02000020000000414D44475055000083AE616D646873612E6B65726E656C7391DE0011AB2E616770725F636F756E7400A52E617267739285AE2E61637475616C5F616363657373A9726561645F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657400A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F62756666657285AE2E61637475616C5F616363657373AA77726974655F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657408A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F627566666572B92E67726F75705F7365676D656E745F66697865645F73697A6500B62E6B65726E6172675F7365676D656E745F616C69676E08B52E6B65726E6172675F7365676D656E745F73697A6510B82E6D61785F666C61745F776F726B67726F75705F73697A6540A52E6E616D65D9247265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332BB2E707269766174655F7365676D656E745F66697865645F73697A6500B42E726571645F776F726B67726F75705F73697A6593400101AB2E736770725F636F756E7412B12E736770725F7370696C6C5F636F756E7400A72E73796D626F6CD9277265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64B82E756E69666F726D5F776F726B5F67726F75705F73697A6501B32E757365735F64796E616D69635F737461636BC2AB2E766770725F636F756E7403B12E766770725F7370696C6C5F636F756E7400AF2E7761766566726F6E745F73697A6540AD616D646873612E746172676574B9616D6467636E2D616D642D616D646873612D2D676678393432AE616D646873612E76657273696F6E92010200000000000000000000000000000000000000000000000000000000000001000000120307000016000000000000C8010000000000002600000011000600C00500000000000040000000000000000100000001000000010000001A000000800004000404000001000000EAD60688873820480300000003000000010000000000000002000000000000000000000000000000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B640000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000040100000000000000000000000000000000000000000000000000000000000008000AF008C0000000800040000000000800006C000000000000106C0080000007FC08CBF3A0082BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF060080BE020188BE8200022409FF0986FFFF0000FF008BBE0070020000080AB0010000D200100504001050E0010102808000947D700F8CBF80020202010080BFFA02020201B108FF010080BFFA020202014E08FF010080BFFA020202014109FF010080BFFA020202014009FF0103047E010080BFFA02047E024201AF02030202010080BFFA020202014309FF000080BF010089D2017F01006A2082BE090088BF0082008E05FF0586FFFF0000A00086BE0B0087BE0102027E0002007E001070E000010180000081BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF0600000000000000A8040000000000000B000000000000001800000000000000050000000000000034050000000000000A000000000000004E00000000000000F5FEFF6F00000000F00400000000000004000000000000001405000000000000000000000000000000000000000000004952454500000000000000000000000000000000000000000000000000000000010000000000F1FF00000000000000000000000000000000370000000000F1FF03000000000000000000000000000000650000000000F1FF00000000000000000000000000000000930000000000F1FF0C000000000000000000000000000000C60000000000F1FF01000000000000000000000000000000F40000000000F1FF000000000000000000000000000000002B0100000000F1FF00000000000000000000000000000000640100000000F1FF00000000000000000000000000000000E401000000020800002C000000000000000000000000000097010000120307000016000000000000C801000000000000BC01000011000600C0050000000000004000000000000000002E6E6F7465002E64796E73796D002E676E752E68617368002E68617368002E64796E737472002E726F64617461002E74657874002E64796E616D6963002E72656C726F5F70616464696E67002E414D444750552E6770725F6D6178696D756D73002E636F6D6D656E74002E73796D746162002E7368737472746162002E73747274616200007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E707269766174655F7365675F73697A65007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F76677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F61677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D62657265645F73677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F766363007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F666C61745F73637261746368007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F64796E5F73697A65645F737461636B007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F726563757273696F6E007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64005F44594E414D494300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000007000000020000000000000000020000000000000002000000000000A402000000000000000000000000000004000000000000000000000000000000070000000B0000000200000000000000A804000000000000A80400000000000048000000000000000500000001000000080000000000000018000000000000000F000000F6FFFF6F0200000000000000F004000000000000F0040000000000002400000000000000020000000000000008000000000000000000000000000000190000000500000002000000000000001405000000000000140500000000000020000000000000000200000000000000040000000000000004000000000000001F000000030000000200000000000000340500000000000034050000000000004E0000000000000000000000000000000100000000000000000000000000000027000000010000000200000000000000C005000000000000C00500000000000040000000000000000000000000000000400000000000000000000000000000002F00000001000000060000000000000000160000000000000006000000000000000600000000000000000000000000000001000000000000000000000000000035000000060000000300000000000000002C000000000000000C00000000000070000000000000000500000000000000080000000000000010000000000000003E000000080000000300000000000000702C000000000000700C00000000000090030000000000000000000000000000010000000000000000000000000000004D0000000100000000000000000000000000000000000000700C0000000000000000000000000000000000000000000001000000000000000000000000000000620000000100000030000000000000000000000000000000700C00000000000005000000000000000000000000000000010000000000000001000000000000006B0000000200000000000000000000000000000000000000780C00000000000020010000000000000E0000000A00000008000000000000001800000000000000730000000300000000000000000000000000000000000000980D00000000000085000000000000000000000000000000010000000000000000000000000000007D00000003000000000000000000000000000000000000001D0E000000000000ED010000000000000000000000000000010000000000000000000000000000000000000006000800040008000C000400080012001C000000040008000000000014001800"> : vector<5408xi8>
  vm.initializer {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After FoldGlobalsPass (iree-util-fold-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After FuseGlobalsPass (iree-util-fuse-globals) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.initializer {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref immutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref immutable @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref immutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  }
}


// -----// IR Dump After GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_9 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %ref_10 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_9, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_10, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_11 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_11, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x4849503100000000E0140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C000000484950310000000046EBFFFF08000000C4000000010000000400000052EBFFFF300000004000000001000000010000000800000048000000020000000300000000000000020000000000000000000000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000BAEBFFFF2800000004000000C6EBFFFF08000000040000000E000000726564756374696F6E2E6D6C69720000240000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F66333200000000010000000400000020ECFFFF04000000D01300007F454C460201014003000000000000000300E000010000000000000000000000400000000000000010100000000000004C05000040003800080040000F000D000600000004000000400000000000000040000000000000004000000000000000C001000000000000C0010000000000000800000000000000010000000400000000000000000000000000000000000000000000000000000000060000000000000006000000000000001000000000000001000000050000000006000000000000001600000000000000160000000000000006000000000000000600000000000000100000000000000100000006000000000C000000000000002C000000000000002C0000000000007000000000000000000400000000000000100000000000000200000006000000000C000000000000002C000000000000002C00000000000070000000000000007000000000000000080000000000000052E5746404000000000C000000000000002C000000000000002C00000000000070000000000000000004000000000000010000000000000051E57464060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000004000000000200000000000000020000000000000002000000000000A402000000000000A4020000000000000400000000000000070000008E02000020000000414D44475055000083AE616D646873612E6B65726E656C7391DE0011AB2E616770725F636F756E7400A52E617267739285AE2E61637475616C5F616363657373A9726561645F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657400A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F62756666657285AE2E61637475616C5F616363657373AA77726974655F6F6E6C79AE2E616464726573735F7370616365A6676C6F62616CA72E6F666673657408A52E73697A6508AB2E76616C75655F6B696E64AD676C6F62616C5F627566666572B92E67726F75705F7365676D656E745F66697865645F73697A6500B62E6B65726E6172675F7365676D656E745F616C69676E08B52E6B65726E6172675F7365676D656E745F73697A6510B82E6D61785F666C61745F776F726B67726F75705F73697A6540A52E6E616D65D9247265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332BB2E707269766174655F7365676D656E745F66697865645F73697A6500B42E726571645F776F726B67726F75705F73697A6593400101AB2E736770725F636F756E7412B12E736770725F7370696C6C5F636F756E7400A72E73796D626F6CD9277265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64B82E756E69666F726D5F776F726B5F67726F75705F73697A6501B32E757365735F64796E616D69635F737461636BC2AB2E766770725F636F756E7403B12E766770725F7370696C6C5F636F756E7400AF2E7761766566726F6E745F73697A6540AD616D646873612E746172676574B9616D6467636E2D616D642D616D646873612D2D676678393432AE616D646873612E76657273696F6E92010200000000000000000000000000000000000000000000000000000000000001000000120307000016000000000000C8010000000000002600000011000600C00500000000000040000000000000000100000001000000010000001A000000800004000404000001000000EAD60688873820480300000003000000010000000000000002000000000000000000000000000000007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B640000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000040100000000000000000000000000000000000000000000000000000000000008000AF008C0000000800040000000000800006C000000000000106C0080000007FC08CBF3A0082BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF060080BE020188BE8200022409FF0986FFFF0000FF008BBE0070020000080AB0010000D200100504001050E0010102808000947D700F8CBF80020202010080BFFA02020201B108FF010080BFFA020202014E08FF010080BFFA020202014109FF010080BFFA020202014009FF0103047E010080BFFA02047E024201AF02030202010080BFFA020202014309FF000080BF010089D2017F01006A2082BE090088BF0082008E05FF0586FFFF0000A00086BE0B0087BE0102027E0002007E001070E000010180000081BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF000080BF0600000000000000A8040000000000000B000000000000001800000000000000050000000000000034050000000000000A000000000000004E00000000000000F5FEFF6F00000000F00400000000000004000000000000001405000000000000000000000000000000000000000000004952454500000000000000000000000000000000000000000000000000000000010000000000F1FF00000000000000000000000000000000370000000000F1FF03000000000000000000000000000000650000000000F1FF00000000000000000000000000000000930000000000F1FF0C000000000000000000000000000000C60000000000F1FF01000000000000000000000000000000F40000000000F1FF000000000000000000000000000000002B0100000000F1FF00000000000000000000000000000000640100000000F1FF00000000000000000000000000000000E401000000020800002C000000000000000000000000000097010000120307000016000000000000C801000000000000BC01000011000600C0050000000000004000000000000000002E6E6F7465002E64796E73796D002E676E752E68617368002E68617368002E64796E737472002E726F64617461002E74657874002E64796E616D6963002E72656C726F5F70616464696E67002E414D444750552E6770725F6D6178696D756D73002E636F6D6D656E74002E73796D746162002E7368737472746162002E73747274616200007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E707269766174655F7365675F73697A65007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F76677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D5F61677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6E756D62657265645F73677072007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F766363007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E757365735F666C61745F73637261746368007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F64796E5F73697A65645F737461636B007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6861735F726563757273696F6E007265647563655F64697370617463685F305F726564756374696F6E5F387836345F663332007265647563655F64697370617463685F305F726564756374696F6E5F387836345F6633322E6B64005F44594E414D494300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000007000000020000000000000000020000000000000002000000000000A402000000000000000000000000000004000000000000000000000000000000070000000B0000000200000000000000A804000000000000A80400000000000048000000000000000500000001000000080000000000000018000000000000000F000000F6FFFF6F0200000000000000F004000000000000F0040000000000002400000000000000020000000000000008000000000000000000000000000000190000000500000002000000000000001405000000000000140500000000000020000000000000000200000000000000040000000000000004000000000000001F000000030000000200000000000000340500000000000034050000000000004E0000000000000000000000000000000100000000000000000000000000000027000000010000000200000000000000C005000000000000C00500000000000040000000000000000000000000000000400000000000000000000000000000002F00000001000000060000000000000000160000000000000006000000000000000600000000000000000000000000000001000000000000000000000000000035000000060000000300000000000000002C000000000000000C00000000000070000000000000000500000000000000080000000000000010000000000000003E000000080000000300000000000000702C000000000000700C00000000000090030000000000000000000000000000010000000000000000000000000000004D0000000100000000000000000000000000000000000000700C0000000000000000000000000000000000000000000001000000000000000000000000000000620000000100000030000000000000000000000000000000700C00000000000005000000000000000000000000000000010000000000000001000000000000006B0000000200000000000000000000000000000000000000780C00000000000020010000000000000E0000000A00000008000000000000001800000000000000730000000300000000000000000000000000000000000000980D00000000000085000000000000000000000000000000010000000000000000000000000000007D00000003000000000000000000000000000000000000001D0E000000000000ED010000000000000000000000000000010000000000000000000000000000000000000006000800040008000C000400080012001C000000040008000000000014001800"> : vector<5408xi8>
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

// -----// IR Dump After DropCompilerHintsPass (iree-util-drop-compiler-hints) //----- //
module attributes {vm.toplevel} {
  vm.module public @module {
    vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
    vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
    vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
    vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
    vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
    vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
      %c1 = vm.const.i32 1
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %zero = vm.const.i32.zero
      %c32 = vm.const.i64 32
      %c2048 = vm.const.i64 2048
      %zero_0 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
      vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
      vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
      vm.return %ref : !vm.ref<!hal.command_buffer>
    }
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
    vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
    vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
    vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
      %c16 = vm.const.i32 16
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c3075 = vm.const.i32 3075
      %c48 = vm.const.i32 48
      %c8 = vm.const.i64 8
      %c64 = vm.const.i64 64
      %c2048 = vm.const.i64 2048
      %c32 = vm.const.i64 32
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c-1_0 = vm.const.i32 -1
      %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
      %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb2, ^bb1
    ^bb1:  // pred: ^bb0
      %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_5 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      vm.fail %0, "failed to wait on timepoint"
    }
    vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
    vm.export @__init
    vm.func private @__init() {
      %c1 = vm.const.i32 1
      %null = vm.const.ref.zero : !vm.buffer
      %c14 = vm.const.i32 14
      %c-1 = vm.const.i64 -1
      %c18 = vm.const.i32 18
      %zero = vm.const.i32.zero
      %zero_0 = vm.const.i64.zero
      %c1_1 = vm.const.i64 1
      %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
      %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
      %1 = vm.ext.i32.i64.s %0 : i32 -> i64
      vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
    ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
      %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
      %5 = vm.xor.i32 %rnz, %c1 : i32
      %slt = vm.cmp.lt.i64.s %2, %1 : i64
      %6 = vm.and.i32 %5, %slt : i32
      vm.cond_br %6, ^bb2, ^bb5
    ^bb2:  // pred: ^bb1
      %7 = vm.trunc.i64.i32 %2 : i64 -> i32
      %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
      %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
      %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
      %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz = vm.cmp.nz.i64 %8#1 : i64
      %9 = vm.select.i32 %8#0, %nz, %zero : i32
      vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
    ^bb3:  // pred: ^bb2
      %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_3 = vm.cmp.nz.i64 %10#1 : i64
      %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
      vm.br ^bb4(%11 : i32)
    ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
      %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
      %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
      %14 = vm.add.i64 %3, %13 : i64
      %15 = vm.and.i32 %12, %eq : i32
      %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
      %16 = vm.add.i64 %2, %c1_1 : i64
      vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
    ^bb5:  // pred: ^bb1
      vm.cond_br %5, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
    ^bb7:  // pred: ^bb5
      %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
      %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
      %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %nz_7 = vm.cmp.nz.i64 %17#1 : i64
      %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
      %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
      %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
      vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
      vm.cond_br %eq_8, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
      %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
      vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
      %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
      vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
      vm.return
    ^bb9:  // pred: ^bb7
      vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
    }
  }
}


// -----// IR Dump After GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.br ^bb10
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  ^bb10:  // pred: ^bb8
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
  %c1 = vm.const.i32 1
  %c8 = vm.const.i32 8
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %zero = vm.const.i32.zero
  %c32 = vm.const.i64 32
  %c2048 = vm.const.i64 2048
  %zero_0 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
  %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
  vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
  vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
  vm.return %ref : !vm.ref<!hal.command_buffer>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
  %c16 = vm.const.i32 16
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %c3075 = vm.const.i32 3075
  %c48 = vm.const.i32 48
  %c8 = vm.const.i64 8
  %c64 = vm.const.i64 64
  %c2048 = vm.const.i64 2048
  %c32 = vm.const.i64 32
  %zero = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c-1_0 = vm.const.i32 -1
  %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
  %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
  %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %0, ^bb2, ^bb1
^bb1:  // pred: ^bb0
  %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_5 : !vm.ref<!hal.buffer_view>
^bb2:  // pred: ^bb0
  vm.fail %0, "failed to wait on timepoint"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %c1 = vm.const.i32 1
  %null = vm.const.ref.zero : !vm.buffer
  %c14 = vm.const.i32 14
  %c-1 = vm.const.i64 -1
  %c18 = vm.const.i32 18
  %zero = vm.const.i32.zero
  %zero_0 = vm.const.i64.zero
  %c1_1 = vm.const.i64 1
  %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
  %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
  %1 = vm.ext.i32.i64.s %0 : i32 -> i64
  vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
  %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
  %5 = vm.xor.i32 %rnz, %c1 : i32
  %slt = vm.cmp.lt.i64.s %2, %1 : i64
  %6 = vm.and.i32 %5, %slt : i32
  vm.cond_br %6, ^bb2, ^bb5
^bb2:  // pred: ^bb1
  %7 = vm.trunc.i64.i32 %2 : i64 -> i32
  %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
  %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
  %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
  %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz = vm.cmp.nz.i64 %8#1 : i64
  %9 = vm.select.i32 %8#0, %nz, %zero : i32
  vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
^bb3:  // pred: ^bb2
  %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
  %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
  %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_3 = vm.cmp.nz.i64 %10#1 : i64
  %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
  vm.br ^bb4(%11 : i32)
^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
  %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
  %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
  %14 = vm.add.i64 %3, %13 : i64
  %15 = vm.and.i32 %12, %eq : i32
  %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
  %16 = vm.add.i64 %2, %c1_1 : i64
  vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
^bb5:  // pred: ^bb1
  vm.cond_br %5, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
^bb7:  // pred: ^bb5
  %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
  %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
  %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %nz_7 = vm.cmp.nz.i64 %17#1 : i64
  %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
  %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
  %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
  vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
  vm.cond_br %eq_8, ^bb8, ^bb9
^bb8:  // pred: ^bb7
  %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
  %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
  vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
  vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.return
^bb9:  // pred: ^bb7
  vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

// -----// IR Dump After DropCompilerHintsPass (iree-util-drop-compiler-hints) //----- //
vm.module public @module {
  vm.global.ref private mutable @__device_0 : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}}
  vm.export @__init
  vm.func private @__init() {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

// -----// IR Dump After OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 17, export_funcs = 2, internal_funcs = 3, global_bytes = 0, global_refs = 3, rodatas = 7, rwdatas = 0>} {
  vm.global.ref private mutable @__device_0 {ordinal = 0 : i32} : !vm.ref<!hal.device>
  vm.global.ref private mutable @__device_0_executable_0_reduce_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.global.ref private mutable @__reduce_memoize_result_0_device_0 {ordinal = 2 : i32} : !vm.ref<!hal.command_buffer>
  vm.rodata private @_utf8_hal_device_id_C6650FF277232B5A {alignment = 1 : i64, ordinal = 0 : i32} "hal.device.id"
  vm.rodata private @_utf8_hip_2D25314D056B7F99 {alignment = 1 : i64, ordinal = 1 : i32} "hip"
  vm.rodata private @_utf8_hal_executable_format_E03EECB63A2AAF52 {alignment = 1 : i64, ordinal = 2 : i32} "hal.executable.format"
  vm.rodata private @_utf8_rocm_hsaco_fb_1C72FE9185115983 {alignment = 1 : i64, ordinal = 3 : i32} "rocm-hsaco-fb"
  vm.rodata private @reduce_dispatch_0_rocm_hsaco_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers", ordinal = 4 : i32} dense<"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vector<5408xi8>
  vm.func private @__reduce_memoize_apply() -> !vm.ref<!hal.command_buffer> attributes {inlining_policy = #util.inline.never, ordinal = 0 : i32} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %null = vm.const.ref.zero : !vm.ref<!hal.buffer>
    %c1 = vm.const.i32 1
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %zero = vm.const.i32.zero
    %c32 = vm.const.i64 32
    %c2048 = vm.const.i64 2048
    %zero_0 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__device_0_executable_0_reduce_dispatch_0 = vm.global.load.ref @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref = vm.call @hal.command_buffer.create(%__device_0, %zero, %c3, %c-1, %c2) : (!vm.ref<!hal.device>, i32, i32, i64, i32) -> !vm.ref<!hal.command_buffer>
    vm.call.variadic @hal.command_buffer.dispatch(%ref, %__device_0_executable_0_reduce_dispatch_0, %zero, %c8, %c1, %c1, %zero_0, [], [(%zero, %zero, %null, %zero_0, %c2048), (%zero, %c1, %null, %zero_0, %c32)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32, i64, i32 ..., tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.execution_barrier(%ref, %c28, %c13, %zero_0) : (!vm.ref<!hal.command_buffer>, i32, i32, i64) -> ()
    vm.call @hal.command_buffer.finalize(%ref) : (!vm.ref<!hal.command_buffer>) -> ()
    vm.return %ref : !vm.ref<!hal.command_buffer>
  }
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 0 : i32}
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 1 : i32}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 2 : i32}
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 3 : i32}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %queue_affinity : i64, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {minimum_version = 6 : i32, ordinal = 4 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 5 : i32}
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i64) attributes {ordinal = 6 : i32}
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32, %flags : i64, %constants : i32 ..., %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 7 : i32}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 8 : i32}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 9 : i32}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64, %flags : i64) -> !vm.ref<!hal.buffer> attributes {ordinal = 10 : i32}
  vm.import private @hal.device.queue.execute.indirect(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffer : !vm.ref<!hal.command_buffer>, %flags : i64, %binding_table : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 11 : i32}
  vm.import private @hal.devices.count() -> i32 attributes {nosideeffects, ordinal = 12 : i32}
  vm.import private @hal.devices.get(%index : i32) -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 13 : i32}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 14 : i32}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i64) -> !vm.ref<!hal.fence> attributes {ordinal = 15 : i32}
  vm.import private @hal.fence.await(%timeout_millis : i32, %flags : i64, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 16 : i32, vm.yield}
  vm.rodata private @_utf8_input0_DCE99660CEB3F6B {alignment = 1 : i64, ordinal = 5 : i32} "input0"
  vm.rodata private @_utf8_tensor_FC1814BC4A58F22A {alignment = 1 : i64, ordinal = 6 : i32} "tensor"
  vm.func private @reduce(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}, ordinal = 1 : i32} {
    %c16 = vm.const.i32 16
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c3075 = vm.const.i32 3075
    %c48 = vm.const.i32 48
    %c8 = vm.const.i64 8
    %c64 = vm.const.i64 64
    %c2048 = vm.const.i64 2048
    %c32 = vm.const.i64 32
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c-1_0 = vm.const.i32 -1
    %__device_0 = vm.global.load.ref @__device_0 : !vm.ref<!hal.device>
    %__reduce_memoize_result_0_device_0 = vm.global.load.ref @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    %_utf8_input0_DCE99660CEB3F6B = vm.const.ref.rodata @_utf8_input0_DCE99660CEB3F6B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input0_DCE99660CEB3F6B, %c553648160, %c1, [%c8, %c64]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_1 = vm.call @hal.device.allocator(%__device_0) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_FC1814BC4A58F22A = vm.const.ref.rodata @_utf8_tensor_FC1814BC4A58F22A : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_FC1814BC4A58F22A, %ref_1, %c2048, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_2 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    %ref_3 = vm.call @hal.device.queue.alloca(%__device_0, %c-1, %null, %ref_2, %zero, %c48, %c3075, %c32, %zero) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i64, i32, i32, i64, i64) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.fence.create(%__device_0, %zero) : (!vm.ref<!hal.device>, i64) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute.indirect(%__device_0, %c-1, %ref_2, %ref_4, %__reduce_memoize_result_0_device_0, %zero, [(%ref, %zero, %c2048), (%ref_3, %zero, %c32)]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer>, i64, tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, %zero, [%ref_4]) : (i32, i64, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb2, ^bb1
  ^bb1:  // pred: ^bb0
    %ref_5 = vm.call.variadic @hal.buffer_view.create(%ref_3, %zero, %c32, %c553648160, %c1, [%c8]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_5 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    vm.fail %0, "failed to wait on timepoint"
  }
  vm.export @reduce attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @reduce(%input0: tensor<8x64xf32>) -> (%output0: tensor<8xf32>)"}, ordinal = 0 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 2 : i32} {
    %c1 = vm.const.i32 1
    %null = vm.const.ref.zero : !vm.buffer
    %c14 = vm.const.i32 14
    %c-1 = vm.const.i64 -1
    %c18 = vm.const.i32 18
    %zero = vm.const.i32.zero
    %zero_0 = vm.const.i64.zero
    %c1_1 = vm.const.i64 1
    %null_2 = vm.const.ref.zero : !vm.ref<!hal.device>
    %0 = vm.call @hal.devices.count() {nosideeffects} : () -> i32
    %1 = vm.ext.i32.i64.s %0 : i32 -> i64
    vm.br ^bb1(%zero_0, %zero_0, %null_2 : i64, i64, !vm.ref<!hal.device>)
  ^bb1(%2: i64, %3: i64, %4: !vm.ref<!hal.device>):  // 2 preds: ^bb0, ^bb4
    %rnz = vm.cmp.nz.ref %4 : !vm.ref<!hal.device>
    %5 = vm.xor.i32 %rnz, %c1 : i32
    %slt = vm.cmp.lt.i64.s %2, %1 : i64
    %6 = vm.and.i32 %5, %slt : i32
    vm.cond_br %6, ^bb2, ^bb5
  ^bb2:  // pred: ^bb1
    %7 = vm.trunc.i64.i32 %2 : i64 -> i32
    %ref = vm.call @hal.devices.get(%7) {nosideeffects} : (i32) -> !vm.ref<!hal.device>
    %_utf8_hal_device_id_C6650FF277232B5A = vm.const.ref.rodata @_utf8_hal_device_id_C6650FF277232B5A : !vm.buffer
    %_utf8_hip_2D25314D056B7F99 = vm.const.ref.rodata @_utf8_hip_2D25314D056B7F99 : !vm.buffer
    %8:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_device_id_C6650FF277232B5A, %_utf8_hip_2D25314D056B7F99) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz = vm.cmp.nz.i64 %8#1 : i64
    %9 = vm.select.i32 %8#0, %nz, %zero : i32
    vm.cond_br %9, ^bb3, ^bb4(%zero : i32)
  ^bb3:  // pred: ^bb2
    %_utf8_hal_executable_format_E03EECB63A2AAF52 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %10:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_E03EECB63A2AAF52, %_utf8_rocm_hsaco_fb_1C72FE9185115983) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_3 = vm.cmp.nz.i64 %10#1 : i64
    %11 = vm.select.i32 %10#0, %nz_3, %zero : i32
    vm.br ^bb4(%11 : i32)
  ^bb4(%12: i32):  // 2 preds: ^bb2, ^bb3
    %eq = vm.cmp.eq.i64 %3, %zero_0 : i64
    %13 = vm.select.i64 %12, %c1_1, %zero_0 : i64
    %14 = vm.add.i64 %3, %13 : i64
    %15 = vm.and.i32 %12, %eq : i32
    %ref_4 = vm.select.ref %15, %ref, %null_2 : !vm.ref<!hal.device>
    %16 = vm.add.i64 %2, %c1_1 : i64
    vm.br ^bb1(%16, %14, %ref_4 : i64, i64, !vm.ref<!hal.device>)
  ^bb5:  // pred: ^bb1
    vm.cond_br %5, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    vm.fail %c18, "HAL device `__device_0` not found or unavailable: #hal.device.target<\22hip\22, [#hal.executable.target<\22rocm\22, \22rocm-hsaco-fb\22, {abi = \22hip\22, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver<>, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module<\22iree_default_tuning_spec_gfx942.mlir\22>, iree_codegen.target_info = #iree_gpu.target<arch = \22gfx942\22, features = \22\22, wgp = <compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [<MFMA_F32_16x16x16_BF16>, <MFMA_F32_32x32x8_BF16>, <MFMA_F32_16x16x32_F8E5M2FNUZ>, <MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ>, <MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ>, <MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ>, <MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ>, <MFMA_I32_16x16x32_I8>, <MFMA_I32_32x32x16_I8>, <MFMA_F64_16x16x4_F64>, <MFMA_F32_16x16x4_F32>, <MFMA_F32_16x16x16_F16>, <MFMA_F32_32x32x8_F16>], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384, dma_sizes = [32]>>, ukernels = \22none\22}>]>"
  ^bb7:  // pred: ^bb5
    %_utf8_hal_executable_format_E03EECB63A2AAF52_5 = vm.const.ref.rodata @_utf8_hal_executable_format_E03EECB63A2AAF52 : !vm.buffer
    %_utf8_rocm_hsaco_fb_1C72FE9185115983_6 = vm.const.ref.rodata @_utf8_rocm_hsaco_fb_1C72FE9185115983 : !vm.buffer
    %17:2 = vm.call @hal.device.query.i64(%4, %_utf8_hal_executable_format_E03EECB63A2AAF52_5, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %nz_7 = vm.cmp.nz.i64 %17#1 : i64
    %18 = vm.select.i32 %17#0, %nz_7, %zero : i32
    %19 = vm.select.i64 %18, %zero_0, %c-1 : i64
    %eq_8 = vm.cmp.eq.i64 %19, %zero_0 : i64
    vm.global.store.ref %4, @__device_0 : !vm.ref<!hal.device>
    vm.cond_br %eq_8, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %reduce_dispatch_0_rocm_hsaco_fb = vm.const.ref.rodata @reduce_dispatch_0_rocm_hsaco_fb : !vm.buffer
    %ref_9 = vm.call @hal.executable.create(%4, %c-1, %_utf8_rocm_hsaco_fb_1C72FE9185115983_6, %reduce_dispatch_0_rocm_hsaco_fb, %null) {nosideeffects} : (!vm.ref<!hal.device>, i64, !vm.buffer, !vm.buffer, !vm.buffer) -> !vm.ref<!hal.executable>
    vm.global.store.ref %ref_9, @__device_0_executable_0_reduce_dispatch_0 : !vm.ref<!hal.executable>
    %ref_10 = vm.call @__reduce_memoize_apply() : () -> !vm.ref<!hal.command_buffer>
    vm.global.store.ref %ref_10, @__reduce_memoize_result_0_device_0 : !vm.ref<!hal.command_buffer>
    vm.return
  ^bb9:  // pred: ^bb7
    vm.fail %c14, "HAL device `__device_0` does not support any variant of executable `reduce_dispatch_0`; available formats: [rocm-hsaco-fb]"
  }
}

